#!/usr/bin/env python3
"""
–°–ò–°–¢–ï–ú–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ –≤—Å–µ—Ö PDF —Ñ–∞–π–ª–æ–≤
"""

import sys
import os
from pathlib import Path
import random

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent / "src"))
sys.path.insert(0, str(Path(__file__).parent))

from lysobacter_rag.indexer.indexer import Indexer

print("üîç –°–ò–°–¢–ï–ú–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø")
print("=" * 60)

indexer = Indexer()
stats = indexer.get_collection_stats()

print(f"üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
print(f"   –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats.get('total_chunks', 0)}")
print(f"   –¢–µ–∫—Å—Ç–æ–≤—ã—Ö: {stats.get('text_chunks', 0)}")
print(f"   –¢–∞–±–ª–∏—á–Ω—ã—Ö: {stats.get('table_chunks', 0)}")

# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
from config import config
collection = indexer.chroma_client.get_collection(name=config.CHROMA_COLLECTION_NAME)
all_metadata = collection.get()['metadatas']

sources = {}
for metadata in all_metadata:
    source = metadata.get('source_pdf', 'unknown')
    chunk_type = metadata.get('chunk_type', 'unknown')
    
    if source not in sources:
        sources[source] = {'text': 0, 'table': 0, 'total': 0}
    
    sources[source][chunk_type] = sources[source].get(chunk_type, 0) + 1
    sources[source]['total'] += 1

print(f"\nüìö –ê–ù–ê–õ–ò–ó –ü–û –ò–°–¢–û–ß–ù–ò–ö–ê–ú:")
print("-" * 50)

# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —á–∞–Ω–∫–æ–≤
sorted_sources = sorted(sources.items(), key=lambda x: x[1]['total'], reverse=True)

print(f"{'–§–∞–π–ª':<40} {'–¢–µ–∫—Å—Ç':<8} {'–¢–∞–±–ª–∏—Ü—ã':<8} {'–í—Å–µ–≥–æ':<8}")
print("-" * 70)

text_heavy = []
table_heavy = []
balanced = []
low_content = []

for source, counts in sorted_sources:
    filename = source.replace('.pdf', '')[:35] + '...' if len(source) > 38 else source
    
    print(f"{filename:<40} {counts.get('text', 0):<8} {counts.get('table', 0):<8} {counts['total']:<8}")
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    text_ratio = counts.get('text', 0) / counts['total']
    table_ratio = counts.get('table', 0) / counts['total']
    
    if counts['total'] < 5:
        low_content.append(source)
    elif text_ratio > 0.8:
        text_heavy.append(source)
    elif table_ratio > 0.8:
        table_heavy.append(source)
    else:
        balanced.append(source)

print(f"\nüéØ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ò–°–¢–û–ß–ù–ò–ö–û–í:")
print("-" * 40)
print(f"üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–µ (>80% —Ç–µ–∫—Å—Ç–∞): {len(text_heavy)}")
print(f"üìä –¢–∞–±–ª–∏—á–Ω—ã–µ (>80% —Ç–∞–±–ª–∏—Ü): {len(table_heavy)}")
print(f"‚öñÔ∏è –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ: {len(balanced)}")
print(f"‚ö†Ô∏è –ú–∞–ª–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (<5 —á–∞–Ω–∫–æ–≤): {len(low_content)}")

# –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞
print(f"\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –¢–ï–ö–°–¢–ê:")
print("-" * 40)

# –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã —Ç–µ–∫—Å—Ç–∞
sample_queries = [
    "temperature range growth",
    "cell size morphology",
    "pH range tolerance", 
    "G+C content DNA",
    "catalase oxidase positive",
    "type strain isolated"
]

quality_issues = []

for query in sample_queries:
    results = indexer.search(query, top_k=5)
    
    print(f"\nüîç –ó–∞–ø—Ä–æ—Å: '{query}'")
    
    for i, result in enumerate(results[:3], 1):
        text = result['text']
        source = result['metadata'].get('source_pdf', 'N/A')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞
        issues = []
        
        # –†–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
        if ' - ' in text and any(char.isalnum() for char in text.split(' - ')[0][-1:]):
            issues.append("—Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞")
        
        # –°–ª–∏—Ç–Ω—ã–µ —á–∏—Å–ª–∞/–µ–¥–∏–Ω–∏—Ü—ã
        if any(pattern in text for pattern in ['¬∞C', 'mM', 'pH']):
            if any(f" {unit}" in text for unit in ['C', 'M']):
                issues.append("—Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã")
        
        # OCR –æ—à–∏–±–∫–∏
        if any(char in text for char in ['¬ß', '¬∂', '¬±', '¬ø']):
            issues.append("OCR –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã")
        
        # –ö–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏ (–º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
        if len(text) < 100:
            issues.append("–∫–æ—Ä–æ—Ç–∫–∏–π —á–∞–Ω–∫")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevance = result['relevance_score']
        if relevance < 0.3:
            issues.append("–Ω–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å")
        
        if issues:
            quality_issues.append({
                'source': source,
                'query': query,
                'issues': issues,
                'relevance': relevance,
                'text_preview': text[:100]
            })
        
        status = "‚ùå" if issues else "‚úÖ"
        issues_str = ", ".join(issues) if issues else "OK"
        print(f"   {i}. {source[:25]}... - {relevance:.3f} {status} {issues_str}")

# –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞—É—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
print(f"\nüß¨ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ù–ê–£–ß–ù–´–• –¢–ï–†–ú–ò–ù–û–í:")
print("-" * 40)

scientific_terms = [
    ("Lysobacter", "–Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–æ–¥–∞"),
    ("sp. nov.", "–Ω–æ–≤—ã–π –≤–∏–¥"),
    ("type strain", "—Ç–∏–ø–æ–≤–æ–π —à—Ç–∞–º–º"),
    ("16S rRNA", "–≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –º–∞—Ä–∫–µ—Ä"),
    ("phylogenetic", "—Ñ–∏–ª–æ–≥–µ–Ω–∏—è"),
    ("G+C content", "—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ì–¶"),
    ("¬∞C", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞"),
    ("pH", "–∫–∏—Å–ª–æ—Ç–Ω–æ—Å—Ç—å")
]

for term, description in scientific_terms:
    results = indexer.search(term, top_k=3)
    
    if results:
        avg_relevance = sum(r['relevance_score'] for r in results) / len(results)
        status = "‚úÖ" if avg_relevance > 0.4 else "‚ö†Ô∏è" if avg_relevance > 0.2 else "‚ùå"
        print(f"{status} {term:<15} ({description:<20}) - —Å—Ä. —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_relevance:.3f}")
    else:
        print(f"‚ùå {term:<15} ({description:<20}) - –ù–ï –ù–ê–ô–î–ï–ù")

# –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
print(f"\nüí° –°–ò–°–¢–ï–ú–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
print("-" * 40)

total_issues = len(quality_issues)
total_samples = len(sample_queries) * 3

if total_issues > total_samples * 0.5:
    print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï: –ë–æ–ª–µ–µ 50% –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–º–µ—é—Ç –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞")
    print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ü–û–õ–ù–ê–Ø –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–º")
elif total_issues > total_samples * 0.3:
    print("‚ö†Ô∏è –°–ï–†–¨–ï–ó–ù–û: 30-50% –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–º–µ—é—Ç –ø—Ä–æ–±–ª–µ–º—ã")
    print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
else:
    print("‚úÖ –ü–†–ò–ï–ú–õ–ï–ú–û: –ú–µ–Ω–µ–µ 30% –ø—Ä–æ–±–ª–µ–º")
    print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¢–æ—á–µ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è")

if len(low_content) > len(sorted_sources) * 0.2:
    print(f"üìâ –ü–†–û–ë–õ–ï–ú–ê: {len(low_content)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –º–∞–ª—ã–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º")
    print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞–Ω–∫–∏–Ω–≥–∞")

print(f"\nüìà –ü–õ–ê–ù –£–õ–£–ß–®–ï–ù–ò–ô:")
print("1. –£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä PDF")
print("2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä –∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —á–∞–Ω–∫–æ–≤")
print("3. –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
print("4. –í–Ω–µ–¥—Ä–∏—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π + –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)")
print("5. –£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

print(f"\nüéØ –ü–†–û–ë–õ–ï–ú–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò –î–õ–Ø –ü–†–ò–û–†–ò–¢–ï–¢–ù–û–ô –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–ò:")
for issue in quality_issues[:10]:  # –¢–æ–ø-10 –ø—Ä–æ–±–ª–µ–º
    print(f"   - {issue['source']}: {', '.join(issue['issues'])}") 