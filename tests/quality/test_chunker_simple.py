#!/usr/bin/env python3
"""
–ü–†–û–°–¢–û–ô –¢–ï–°–¢: –£–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ –±–µ–∑ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent / "src"))

from lysobacter_rag.pdf_extractor.scientific_chunker import ScientificTextChunker

def test_simple_chunking():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —É–º–Ω–æ–≥–æ —á–∞–Ω–∫–µ—Ä–∞"""
    
    print("üß¨ –ü–†–û–°–¢–û–ô –¢–ï–°–¢ –£–ú–ù–û–ì–û –ß–ê–ù–ö–ï–†–ê")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞—É—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ –æ YC5194)
    test_text = """
    Lysobacter capsici sp. nov. is a gram-negative, aerobic bacterium isolated from the rhizosphere 
    of pepper plants in South Korea. The type strain YC5194T was isolated from soil samples 
    collected in agricultural fields. Cells are rod-shaped, measuring 0.3-0.5 √ó 2.0-20 Œºm, 
    and are motile by means of a polar flagellum.
    
    The temperature range for growth is 15-37¬∞C, with optimal growth at 28¬∞C. The pH range 
    for growth is 5.5-8.5, with optimal growth at pH 7.0. The strain grows on nutrient agar, 
    tryptic soy agar, and Luria-Bertani agar. The strain is catalase-positive and oxidase-positive.
    
    The G+C content of the genomic DNA is 65.4 mol%. 16S rRNA gene sequence analysis showed 
    the highest similarity to Lysobacter gummosus LMG 18383T with 97.8% sequence identity. 
    Phylogenetic analysis based on 16S rRNA gene sequences placed the strain in the genus Lysobacter.
    
    The strain shows antimicrobial activity against various plant pathogens including 
    Fusarium oxysporum and Pythium ultimum. Based on the phenotypic, chemotaxonomic, 
    and phylogenetic characteristics, strain YC5194T represents a novel species of 
    the genus Lysobacter, for which the name Lysobacter capsici sp. nov. is proposed.
    """
    
    # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è —á–∞–Ω–∫–µ—Ä–∞
    test_elements = [
        {
            'content': test_text,
            'element_type': 'text',
            'page_number': 1,
            'confidence': 0.9,
            'metadata': {
                'extraction_method': 'test',
                'source': 'test_article.pdf'
            }
        }
    ]
    
    print(f"üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(test_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞–Ω–∫–µ—Ä
    chunker = ScientificTextChunker(target_chunk_size=300, overlap=50)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —á–∞–Ω–∫–∏–Ω–≥
    print("\nüöÄ –ü—Ä–∏–º–µ–Ω—è—é —É–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥...")
    
    try:
        chunks = chunker.chunk_extracted_elements(test_elements)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        total_length = sum(len(chunk['content']) for chunk in chunks)
        avg_length = total_length / len(chunks) if chunks else 0
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   –û–±—â–∞—è –¥–ª–∏–Ω–∞: {total_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞: {avg_length:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä: 300 —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á–∞–Ω–∫–∏
        print(f"\nüîç –°–æ–∑–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∏:")
        
        for i, chunk in enumerate(chunks, 1):
            content = chunk['content']
            metadata = chunk['metadata']
            
            importance = metadata.get('scientific_importance', 'unknown')
            key_terms = metadata.get('key_terms', [])
            chunk_type = metadata.get('chunk_type', 'unknown')
            
            print(f"\n   üìù –ß–∞–Ω–∫ {i}:")
            print(f"      –¢–∏–ø: {chunk_type}")
            print(f"      –í–∞–∂–Ω–æ—Å—Ç—å: {importance}")
            print(f"      –î–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"      –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {', '.join(key_terms[:5]) if key_terms else '–Ω–µ—Ç'}")
            print(f"      –¢–µ–∫—Å—Ç: {content[:100]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        print(f"\nüéØ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
        sizes_ok = all(200 <= len(c['content']) <= 450 for c in chunks)
        print(f"   –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤: {'‚úÖ' if sizes_ok else '‚ùå'}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
        important_chunks = [c for c in chunks 
                           if c['metadata'].get('scientific_importance') in ['high', 'critical']]
        importance_ok = len(important_chunks) > 0
        print(f"   –í–∞–∂–Ω—ã–µ —á–∞–Ω–∫–∏ –Ω–∞–π–¥–µ–Ω—ã: {'‚úÖ' if importance_ok else '‚ùå'} ({len(important_chunks)})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        all_terms = []
        for c in chunks:
            all_terms.extend(c['metadata'].get('key_terms', []))
        
        scientific_terms = [t for t in all_terms 
                           if any(sci in t.lower() for sci in ['lysobacter', 'strain', 'ph', '¬∞c'])]
        terms_ok = len(scientific_terms) >= 5
        print(f"   –ù–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {'‚úÖ' if terms_ok else '‚ùå'} ({len(scientific_terms)})")
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        if sizes_ok and importance_ok and terms_ok:
            print(f"\nüèÜ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù: –£–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            return True
        else:
            print(f"\n‚ö†Ô∏è –¢–ï–°–¢ –ß–ê–°–¢–ò–ß–ù–û –ü–†–û–ô–î–ï–ù: –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
            return False
            
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ —á–∞–Ω–∫–∏–Ω–≥–µ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_simple_chunking()
    exit(0 if success else 1) 