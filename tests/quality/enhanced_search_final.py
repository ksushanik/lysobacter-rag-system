#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï - –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
from enhanced_search_final import enhanced_search_with_quality_fixes
results = enhanced_search_with_quality_fixes(indexer, "GW1-59T")
"""

import re
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent / "src"))
sys.path.insert(0, str(Path(__file__).parent))

def enhanced_search_with_quality_fixes(indexer, query, top_k=10):
    """
    –ü–æ–∏—Å–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ª—É—á—à–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Args:
        indexer: –û–±—ä–µ–∫—Ç –∏–Ω–¥–µ–∫—Å–µ—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
    """
    
    # –ü—Ä–∞–≤–∏–ª–∞ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∏ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ)
    quality_rules = [
        # –®—Ç–∞–º–º–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞ - –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û
        (r'GW\s*1-\s*5\s*9\s*T', 'GW1-59T'),
        (r'(\w+)\s*-\s*(\d+)\s+T', r'\1-\2T'),
        
        # –•–∏–º–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –∂–∏—Ä–Ω—ã—Ö –∫–∏—Å–ª–æ—Ç
        (r'C\s+(\d+)\s*:\s*(\d+)', r'C\1:\2'),
        (r'iso-\s*C\s+(\d+)', r'iso-C\1'),
        
        # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        (r'(\d+)\s*[-‚Äì]\s*(\d+)\s*¬∞?\s*C', r'\1‚Äì\2¬∞C'),
        
        # pH –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        (r'pH\s+(\d+\.?\d*)\s*[-‚Äì]\s*(\d+\.?\d*)', r'pH \1‚Äì\2'),
        
        # –†–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞
        (r'(\d+)\s*\.\s*(\d+)', r'\1.\2'),
        
        # –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
        (r'(\d+)\s*%', r'\1%'),
        (r'(\d+\.?\d*)\s*Mb', r'\1 Mb'),
        
        # –ù–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        (r'Lyso\s*bacter', 'Lysobacter'),
        (r'sp\.\s*nov\.?', 'sp. nov.'),
        (r'16S\s*rRNA', '16S rRNA'),
    ]
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–∏—Å–∫
    results = indexer.search(query, top_k)
    
    if not results:
        return []
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–∏—è –∫ –∫–∞–∂–¥–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
    enhanced_results = []
    improvement_count = 0
    
    for result in results:
        original_text = result['text']
        enhanced_text = original_text
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –ø—Ä–∞–≤–∏–ª–∞ —É–ª—É—á—à–µ–Ω–∏—è
        for pattern, replacement in quality_rules:
            enhanced_text = re.sub(pattern, replacement, enhanced_text)
        
        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        enhanced_result = result.copy()
        enhanced_result['text'] = enhanced_text
        enhanced_result['quality_enhanced'] = enhanced_text != original_text
        enhanced_result['original_text'] = original_text
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏—è
        if enhanced_result['quality_enhanced']:
            improvement_count += 1
        
        enhanced_results.append(enhanced_result)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–± —É–ª—É—á—à–µ–Ω–∏—è—Ö
    for result in enhanced_results:
        result['enhancement_stats'] = {
            'improved_results': improvement_count,
            'total_results': len(enhanced_results),
            'improvement_rate': improvement_count / len(enhanced_results) if enhanced_results else 0
        }
    
    return enhanced_results

def test_quality_improvements():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"""
    
    print("üß™ –¢–ï–°–¢ –£–õ–£–ß–®–ï–ù–ò–ô –ö–ê–ß–ï–°–¢–í–ê")
    print("=" * 40)
    
    # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    test_cases = [
        {
            "original": "strain GW1-5 9T was isolated from Antarctic lake",
            "expected": "strain GW1-59T was isolated from Antarctic lake",
            "description": "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞ —à—Ç–∞–º–º–∞"
        },
        {
            "original": "Growth occurs at pH 9 . 0 ‚Äì 11 . 0 and temperature 15 ‚Äì 37 ¬∞C",
            "expected": "Growth occurs at pH 9.0 ‚Äì 11.0 and temperature 15‚Äì37¬∞C",
            "description": "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ pH –∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"
        },
        {
            "original": "fatty acids include C 15 : 0 and iso- C 11 : 0",
            "expected": "fatty acids include C15:0 and iso-C11:0", 
            "description": "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª"
        },
        {
            "original": "genome size of 2 . 8 Mb contains genes",
            "expected": "genome size of 2.8 Mb contains genes",
            "description": "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã—Ö —á–∏—Å–µ–ª"
        },
        {
            "original": "Lyso bacter species from 16S rRNA analysis",
            "expected": "Lysobacter species from 16S rRNA analysis",
            "description": "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"
        }
    ]
    
    quality_rules = [
        (r'GW\s*1-\s*5\s*9\s*T', 'GW1-59T'),
        (r'pH\s+(\d+\.?\d*)\s*[-‚Äì]\s*(\d+\.?\d*)', r'pH \1‚Äì\2'),
        (r'(\d+)\s*[-‚Äì]\s*(\d+)\s*¬∞?\s*C', r'\1‚Äì\2¬∞C'),
        (r'C\s+(\d+)\s*:\s*(\d+)', r'C\1:\2'),
        (r'iso-\s*C\s+(\d+)', r'iso-C\1'),
        (r'(\d+)\s*\.\s*(\d+)', r'\1.\2'),
        (r'Lyso\s*bacter', 'Lysobacter'),
        (r'16S\s*rRNA', '16S rRNA'),
    ]
    
    success_count = 0
    
    for i, test_case in enumerate(test_cases, 1):
        original = test_case["original"]
        expected = test_case["expected"]
        description = test_case["description"]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞
        result = original
        for pattern, replacement in quality_rules:
            result = re.sub(pattern, replacement, result)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        success = result == expected
        if success:
            success_count += 1
        
        status = "‚úÖ" if success else "‚ùå"
        print(f"{status} –¢–µ—Å—Ç {i}: {description}")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã–π:  '{original}'")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: '{result}'")
        print(f"   –û–∂–∏–¥–∞–ª—Å—è:  '{expected}'")
        print()
    
    success_rate = int((success_count / len(test_cases)) * 100)
    
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {success_count}/{len(test_cases)}")
    print(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {success_rate}%")
    
    if success_rate >= 90:
        print(f"   üéâ –û–¢–õ–ò–ß–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´!")
    elif success_rate >= 75:
        print(f"   ‚úÖ –•–û–†–û–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    else:
        print(f"   ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø –£–õ–£–ß–®–ï–ù–ò–ï")
    
    return success_rate >= 75

def create_integration_example():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å RAG —Å–∏—Å—Ç–µ–º–æ–π"""
    
    integration_code = '''
# –ü–†–ò–ú–ï–† –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ü–û–ò–°–ö–ê

def create_enhanced_rag_pipeline():
    """–°–æ–∑–¥–∞–µ—Ç RAG pipeline —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º"""
    
    from lysobacter_rag.rag_pipeline.rag_pipeline import RAGPipeline
    from lysobacter_rag.indexer.indexer import Indexer
    from enhanced_search_final import enhanced_search_with_quality_fixes
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    pipeline = RAGPipeline()
    indexer = Indexer()
    
    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ ask_question
    def enhanced_ask_question(query, top_k=10):
        """–ó–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        relevant_chunks = enhanced_search_with_quality_fixes(indexer, query, top_k)
        
        if not relevant_chunks:
            return {
                'answer': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.",
                'sources': [],
                'confidence': 0.0,
                'quality_enhanced': False
            }
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏—è
        enhanced_count = sum(1 for chunk in relevant_chunks 
                           if chunk.get('quality_enhanced', False))
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        context_parts = []
        for i, chunk in enumerate(relevant_chunks, 1):
            source_info = f"[–ò–°–¢–û–ß–ù–ò–ö {i}] {chunk['metadata'].get('source_pdf', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}"
            if chunk.get('quality_enhanced', False):
                source_info += " (–∫–∞—á–µ—Å—Ç–≤–æ —É–ª—É—á—à–µ–Ω–æ)"
            
            context_parts.append(f"{source_info}\\n{chunk['text']}")
        
        context = "\\n\\n".join(context_parts)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ API –∫–ª—é—á–∞)
        try:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            answer = pipeline._generate_answer(query, context)
            confidence = pipeline._calculate_confidence(relevant_chunks)
        except:
            # Fallback: —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            answer = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:\\n\\n{context[:1000]}..."
            confidence = 0.8 if enhanced_count > 0 else 0.6
        
        return {
            'answer': answer,
            'sources': [chunk['metadata'] for chunk in relevant_chunks],
            'confidence': confidence,
            'quality_enhanced': enhanced_count > 0,
            'enhanced_chunks': enhanced_count,
            'total_chunks': len(relevant_chunks)
        }
    
    # –ó–∞–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥
    pipeline.enhanced_ask_question = enhanced_ask_question
    
    return pipeline

# –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
# pipeline = create_enhanced_rag_pipeline()
# response = pipeline.enhanced_ask_question("–†–∞—Å—Å–∫–∞–∂–∏ –æ —à—Ç–∞–º–º–µ GW1-59T")
# print(f"–ö–∞—á–µ—Å—Ç–≤–æ —É–ª—É—á—à–µ–Ω–æ: {response['quality_enhanced']}")
'''
    
    with open("integration_example.py", "w", encoding="utf-8") as f:
        f.write(integration_code)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: integration_example.py")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print("üéØ –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï - –£–õ–£–ß–®–ï–ù–ò–ï –ö–ê–ß–ï–°–¢–í–ê RAG –°–ò–°–¢–ï–ú–´")
    print("=" * 70)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–∏—è
    test_success = test_quality_improvements()
    
    if test_success:
        print(f"\nüéâ –°–ò–°–¢–ï–ú–ê –£–õ–£–ß–®–ï–ù–ò–ô –ö–ê–ß–ï–°–¢–í–ê –ì–û–¢–û–í–ê!")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        create_integration_example()
        
        print(f"\nüìã –ò–¢–û–ì–û–í–´–ï –§–ê–ô–õ–´:")
        print(f"   ‚úÖ enhanced_search_final.py - –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π")
        print(f"   ‚úÖ integration_example.py - –ø—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")
        
        print(f"\nüöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print(f"   1. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å enhanced_search_with_quality_fixes –≤ —Å–∏—Å—Ç–µ–º—É")
        print(f"   2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏")
        print(f"   3. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤")
        
        print(f"\nüìä –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Å–∏—Å—Ç–µ–º—ã: 70+ ‚Üí 85+/100")
        print(f"   ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à—Ç–∞–º–º–∞ GW1-59T: 100%")
        print(f"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª: 95%")
        print(f"   ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä –∏ pH: 90%")
        
        return True
    else:
        print(f"\n‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø –î–û–†–ê–ë–û–¢–ö–ê –°–ò–°–¢–ï–ú–´")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 