#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ RAG —Å–∏—Å—Ç–µ–º—ã –¥–ª—è —à—Ç–∞–º–º–æ–≤
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ NotebookLM
"""

import sys
import os
sys.path.append('src')

from src.lysobacter_rag.rag_pipeline.enhanced_rag import EnhancedRAGPipeline
import json
from datetime import datetime

def test_strain_questions():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ —à—Ç–∞–º–º–∞—Ö"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
    try:
        rag = EnhancedRAGPipeline()
        print("‚úÖ RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        {
            "question": "–ö–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ç–∞–º–º–∞ Lysobacter capsici YC5194?",
            "strain": "YC5194",
            "expected_topics": [
                "–ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ä–∏–∑–æ—Å—Ñ–µ—Ä—ã –ø–µ—Ä—Ü–∞",
                "–º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
                "—É—Å–ª–æ–≤–∏—è —Ä–æ—Å—Ç–∞",
                "–±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞",
                "–ø—Ä–æ—Ç–∏–≤–æ–≥—Ä–∏–±–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                "—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∞–Ω—Ç–∏–±–∏–æ—Ç–∏–∫–∞–º"
            ]
        },
        {
            "question": "–ß—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –æ —à—Ç–∞–º–º–µ GW1-59T?",
            "strain": "GW1-59T", 
            "expected_topics": [
                "Lysobacter antarcticus sp. nov.",
                "–∏–∑–æ–ª—è—Ü–∏—è –∏–∑ –ê–Ω—Ç–∞—Ä–∫—Ç–∏–¥—ã",
                "–º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è",
                "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–µ —É—Å–ª–æ–≤–∏—è",
                "–≥–µ–Ω–æ–º–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏",
                "–±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞"
            ]
        }
    ]
    
    results = {}
    
    for i, test_case in enumerate(test_questions, 1):
        print(f"\nüîç –¢–µ—Å—Ç {i}: {test_case['strain']}")
        print("-" * 40)
        print(f"–í–æ–ø—Ä–æ—Å: {test_case['question']}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç —Å–∏—Å—Ç–µ–º—ã
            result = rag.ask_question(
                query=test_case['question'],
                top_k=10
            )
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            response = {
                'answer': result.answer,
                'chunks': [{'metadata': source} for source in result.sources],
                'relevance_score': result.confidence
            }
            
            print(f"\nüìù –û—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã:")
            print(response['answer'])
            
            print(f"\nüìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
            print(f"- –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(response.get('chunks', []))}")
            print(f"- –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {response.get('relevance_score', 'N/A')}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            results[test_case['strain']] = {
                "question": test_case['question'],
                "answer": response['answer'],
                "chunks_count": len(response.get('chunks', [])),
                "relevance": response.get('relevance_score'),
                "expected_topics": test_case['expected_topics'],
                "sources": [chunk.get('metadata', {}).get('source', 'Unknown') 
                          for chunk in response.get('chunks', [])]
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            results[test_case['strain']] = {
                "question": test_case['question'],
                "error": str(e)
            }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"tests/quality/strain_test_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")
    
    return results

def analyze_coverage(our_answer: str, expected_topics: list) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ç–µ–º –≤ –æ—Ç–≤–µ—Ç–µ"""
    
    coverage = {}
    our_answer_lower = our_answer.lower()
    
    for topic in expected_topics:
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        topic_words = topic.lower().split()
        found_words = sum(1 for word in topic_words if word in our_answer_lower)
        coverage_percent = (found_words / len(topic_words)) * 100 if topic_words else 0
        
        coverage[topic] = {
            "covered": coverage_percent > 50,  # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª—å—à–µ 50% —Å–ª–æ–≤ —Ç–µ–º—ã
            "coverage_percent": coverage_percent,
            "found_words": found_words,
            "total_words": len(topic_words)
        }
    
    return coverage

def compare_with_notebooklm():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ NotebookLM"""
    
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    results = test_strain_questions()
    
    if not results:
        print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    analysis = {}
    
    for strain, result in results.items():
        if 'error' in result:
            print(f"\n‚ùå {strain}: –û—à–∏–±–∫–∞ - {result['error']}")
            continue
            
        print(f"\nüî¨ –ê–Ω–∞–ª–∏–∑ –¥–ª—è —à—Ç–∞–º–º–∞ {strain}")
        print("-" * 30)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º
        coverage = analyze_coverage(result['answer'], result['expected_topics'])
        
        covered_topics = sum(1 for topic_data in coverage.values() if topic_data['covered'])
        total_topics = len(coverage)
        coverage_percentage = (covered_topics / total_topics) * 100 if total_topics > 0 else 0
        
        print(f"üìà –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º: {covered_topics}/{total_topics} ({coverage_percentage:.1f}%)")
        
        for topic, data in coverage.items():
            status = "‚úÖ" if data['covered'] else "‚ùå"
            print(f"  {status} {topic} ({data['coverage_percent']:.0f}%)")
        
        analysis[strain] = {
            "coverage_percentage": coverage_percentage,
            "covered_topics": covered_topics,
            "total_topics": total_topics,
            "coverage_details": coverage,
            "chunks_used": result['chunks_count'],
            "sources": result['sources']
        }
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:")
    print("-" * 30)
    
    avg_coverage = sum(a['coverage_percentage'] for a in analysis.values()) / len(analysis) if analysis else 0
    
    if avg_coverage < 70:
        print("üîß –ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º - –Ω—É–∂–Ω–æ —É–ª—É—á—à–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    if avg_coverage < 50:
        print("‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ù–û: –°–∏—Å—Ç–µ–º–∞ —É–ø—É—Å–∫–∞–µ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –≤–∞–∂–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
    
    return analysis

if __name__ == "__main__":
    results = compare_with_notebooklm() 