#!/usr/bin/env python3
"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Ç–µ—Å—Ç–∞ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏
–§–∏–∫—Å: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""

import sys
import os
sys.path.append('src')

from src.lysobacter_rag.rag_pipeline.enhanced_rag import EnhancedRAGPipeline
from src.lysobacter_rag.rag_pipeline.structured_strain_analyzer import StructuredStrainAnalyzer
from src.lysobacter_rag.indexer import Indexer
import json
from datetime import datetime

def test_fixed_strain_responses():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ò–°–ü–†–ê–í–õ–ï–ù–ù–£–Æ —Å–∏—Å—Ç–µ–º—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    print("üõ†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    try:
        indexer = Indexer()
        strain_analyzer = StructuredStrainAnalyzer()
        print("‚úÖ –ò–Ω–¥–µ–∫—Å–µ—Ä –∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —à—Ç–∞–º–º–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        {
            "question": "–ö–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ç–∞–º–º–∞ Lysobacter capsici YC5194?",
            "strain": "YC5194",
            "strain_full_name": "Lysobacter capsici YC5194",
            "search_terms": ["YC5194", "Lysobacter capsici", "capsici YC5194"]
        },
        {
            "question": "–ß—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –æ —à—Ç–∞–º–º–µ GW1-59T?",
            "strain": "GW1-59T",
            "strain_full_name": "GW1-59T",
            "search_terms": ["GW1-59T", "Lysobacter antarcticus", "antarcticus GW1"]
        }
    ]
    
    results = {}
    
    for i, test_case in enumerate(test_questions, 1):
        print(f"\nüî¨ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ç–µ—Å—Ç {i}: {test_case['strain']}")
        print("-" * 50)
        print(f"–í–æ–ø—Ä–æ—Å: {test_case['question']}")
        
        try:
            # –®–∞–≥ 1: –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
            all_chunks = []
            for search_term in test_case['search_terms']:
                print(f"  üîç –ò—â—É: '{search_term}'")
                chunks = indexer.search(search_term, top_k=8)
                all_chunks.extend(chunks)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID
            unique_chunks = {}
            for chunk in all_chunks:
                chunk_id = chunk.get('id', str(hash(chunk.get('text', ''))))
                if chunk_id not in unique_chunks:
                    unique_chunks[chunk_id] = chunk
            
            final_chunks = list(unique_chunks.values())
            print(f"  üìä –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {len(final_chunks)}")
            
            # –®–∞–≥ 2: –ü–†–ê–í–ò–õ–¨–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_parts = []
            for chunk in final_chunks:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–ª—è
                text = chunk.get('text', '')  # –û—Å–Ω–æ–≤–Ω–æ–µ –ø–æ–ª–µ —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                if text:
                    context_parts.append(text)
                    print(f"    ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —á–∞–Ω–∫: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                else:
                    print(f"    ‚ùå –ü—É—Å—Ç–æ–π —á–∞–Ω–∫: {list(chunk.keys())}")
            
            context = "\n\n".join(context_parts)
            print(f"  üìÑ –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –®–∞–≥ 3: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if context.strip():
                print(f"  üî¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —à—Ç–∞–º–º {test_case['strain_full_name']}")
                
                strain_characteristics = strain_analyzer.analyze_strain_from_context(
                    context, test_case['strain_full_name']
                )
                
                # –®–∞–≥ 4: –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                structured_answer = strain_analyzer.format_structured_response(strain_characteristics)
                
                print(f"\nüìù –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:")
                print(structured_answer)
                
                print(f"\nüìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
                filled_categories = _count_filled_categories(strain_characteristics)
                print(f"- –ó–∞–ø–æ–ª–Ω–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {filled_categories}/8 ({filled_categories/8*100:.1f}%)")
                print(f"- –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {strain_characteristics.confidence_score:.3f}")
                print(f"- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(final_chunks)}")
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                print(f"\nüìã –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                categories = [
                    ("üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", strain_characteristics.classification),
                    ("üìç –ü—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ", strain_characteristics.origin),
                    ("üî¨ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è", strain_characteristics.morphology),
                    ("üå°Ô∏è –£—Å–ª–æ–≤–∏—è —Ä–æ—Å—Ç–∞", strain_characteristics.growth_conditions),
                    ("‚öóÔ∏è –ë–∏–æ—Ö–∏–º–∏—è", strain_characteristics.biochemical_properties),
                    ("üß™ –•–µ–º–æ—Ç–∞–∫—Å–æ–Ω–æ–º–∏—è", strain_characteristics.chemotaxonomy),
                    ("üß¨ –ì–µ–Ω–æ–º–∏–∫–∞", strain_characteristics.genomics),
                    ("ü¶† –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", strain_characteristics.biological_activity)
                ]
                
                for name, data in categories:
                    status = "‚úÖ" if data else "‚ùå"
                    count = len(data) if data else 0
                    print(f"  {status} {name}: {count} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                results[test_case['strain']] = {
                    "question": test_case['question'],
                    "structured_answer": structured_answer,
                    "context_length": len(context),
                    "structure_confidence": strain_characteristics.confidence_score,
                    "chunks_count": len(final_chunks),
                    "categories_filled": filled_categories,
                    "strain_characteristics": {
                        "classification": strain_characteristics.classification,
                        "origin": strain_characteristics.origin,
                        "morphology": strain_characteristics.morphology,
                        "growth_conditions": strain_characteristics.growth_conditions,
                        "biochemical": strain_characteristics.biochemical_properties,
                        "chemotaxonomy": strain_characteristics.chemotaxonomy,
                        "genomics": strain_characteristics.genomics,
                        "biological_activity": strain_characteristics.biological_activity,
                        "unique_features": strain_characteristics.unique_features
                    }
                }
            else:
                print(f"\n‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—Å–µ –µ—â–µ –ø—É—Å—Ç –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
                results[test_case['strain']] = {
                    "question": test_case['question'],
                    "error": "–ü—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
                    "chunks_count": len(final_chunks)
                }
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            import traceback
            traceback.print_exc()
            results[test_case['strain']] = {
                "question": test_case['question'],
                "error": str(e)
            }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"tests/quality/fixed_strain_test_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    print(f"\nüéØ –ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô")
    print("=" * 50)
    
    total_score = 0
    for strain, result in results.items():
        if 'error' not in result:
            categories_percent = (result.get('categories_filled', 0) / 8) * 100
            confidence = result.get('structure_confidence', 0) * 100
            
            score = (categories_percent + confidence) / 2
            total_score += score
            
            print(f"\nüî¨ {strain}:")
            print(f"   üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {result.get('categories_filled', 0)}/8 ({categories_percent:.1f}%)")
            print(f"   üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1f}%")
            print(f"   üìà –û–±—â–∏–π –±–∞–ª–ª: {score:.1f}/100")
            
            if score >= 70:
                print(f"   üèÜ –û–¢–õ–ò–ß–ù–´–ô —Ä–µ–∑—É–ª—å—Ç–∞—Ç!")
            elif score >= 50:
                print(f"   ‚úÖ –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            elif score >= 30:
                print(f"   ‚ö†Ô∏è –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ")
            else:
                print(f"   ‚ùå –ù—É–∂–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è")
    
    avg_score = total_score / len([r for r in results.values() if 'error' not in r]) if results else 0
    print(f"\nüèÅ –°–†–ï–î–ù–ò–ô –ë–ê–õ–õ –°–ò–°–¢–ï–ú–´: {avg_score:.1f}/100")
    
    return results

def _count_filled_categories(characteristics) -> int:
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
    categories = [
        characteristics.classification,
        characteristics.origin,
        characteristics.morphology,
        characteristics.growth_conditions,
        characteristics.biochemical_properties,
        characteristics.chemotaxonomy,
        characteristics.genomics,
        characteristics.biological_activity
    ]
    
    return sum(1 for cat in categories if cat)

def compare_with_notebooklm():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ NotebookLM"""
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° NOTEBOOKLM")
    print("-" * 30)
    print("üéØ –¶–ï–õ–ò:")
    print("- YC5194: 95%+ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º (–±—ã–ª–æ 0%)")
    print("- GW1-59T: 95%+ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–º (–±—ã–ª–æ 66.7%)")
    print("- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: –ß–µ—Ç–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    print("- –î–µ—Ç–∞–ª—å–Ω–æ—Å—Ç—å: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ vs –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã")

if __name__ == "__main__":
    results = test_fixed_strain_responses()
    compare_with_notebooklm() 