#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
"""
import sys
sys.path.insert(0, 'src')

from lysobacter_rag.indexer import Indexer
import re
from typing import List, Dict, Any

class ImprovedSearchEngine:
    def __init__(self):
        self.indexer = Indexer()
        self.collection = self.indexer.collection
        
    def hybrid_search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π + –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        """
        print(f"üîç –í—ã–ø–æ–ª–Ω—è—é –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è: '{query}'")
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —à—Ç–∞–º–º—ã)
        exact_matches = self._exact_keyword_search(query, top_k=top_k)
        
        # 2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        semantic_results = self.indexer.search(query, top_k=top_k)
        
        # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        combined_results = self._combine_and_rank_results(
            exact_matches, semantic_results, query
        )
        
        return combined_results[:top_k]
    
    def _exact_keyword_search(self, query: str, top_k: int = 50) -> List[Dict[str, Any]]:
        """
        –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —à—Ç–∞–º–º–æ–≤
        strain_patterns = [
            r'\b[A-Z]{1,3}\d{3,5}[A-Z]?\b',  # YC5194, GW1-59T –∏ —Ç.–¥.
            r'\b[A-Z]+-?\d+[A-Z]*\b',        # —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        ]
        
        keywords = [query.strip()]
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —à—Ç–∞–º–º–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
        for pattern in strain_patterns:
            matches = re.findall(pattern, query.upper())
            keywords.extend(matches)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        all_data = self.collection.get()
        
        exact_results = []
        
        if all_data['documents']:
            for i, doc in enumerate(all_data['documents']):
                doc_upper = doc.upper()
                score = 0
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                for keyword in keywords:
                    keyword_upper = keyword.upper()
                    count = doc_upper.count(keyword_upper)
                    if count > 0:
                        score += count * 10  # –í—ã—Å–æ–∫–∏–π –≤–µ—Å –¥–ª—è —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                
                if score > 0:
                    metadata = all_data['metadatas'][i]
                    exact_results.append({
                        'text': doc,
                        'metadata': metadata,
                        'relevance_score': min(score / 100.0, 1.0),
                        'search_type': 'exact'
                    })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        exact_results.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        print(f"üìç –ù–∞–π–¥–µ–Ω–æ {len(exact_results)} —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
        
        return exact_results[:top_k]
    
    def _combine_and_rank_results(self, exact_results, semantic_results, query):
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–æ—á–Ω—ã–µ –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        combined = {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        for result in exact_results:
            doc_text = result['text']
            if doc_text not in combined:
                combined[doc_text] = result
                combined[doc_text]['final_score'] = result['relevance_score'] + 0.5  # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ—á–Ω–æ—Å—Ç—å
            
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in semantic_results:
            doc_text = result['text']
            if doc_text not in combined:
                combined[doc_text] = result
                combined[doc_text]['final_score'] = result['relevance_score']
                combined[doc_text]['search_type'] = 'semantic'
            else:
                # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —É–∂–µ –µ—Å—Ç—å, –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å–∫–æ—Ä—ã
                combined[doc_text]['final_score'] += result['relevance_score'] * 0.3
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É —Å–∫–æ—Ä—É
        final_results = list(combined.values())
        final_results.sort(key=lambda x: x['final_score'], reverse=True)
        
        return final_results

def test_improved_search():
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞
    """
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ô –°–ò–°–¢–ï–ú–´ –ü–û–ò–°–ö–ê")
    print("=" * 60)
    
    search_engine = ImprovedSearchEngine()
    
    test_queries = [
        "YC5194",
        "Lysobacter capsici YC5194", 
        "–ö–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ç–∞–º–º–∞ Lysobacter capsici YC5194?",
        "GW1-59T",
        "–ß—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –æ —à—Ç–∞–º–º–µ GW1-59T?"
    ]
    
    for query in test_queries:
        print(f"\nüß™ –¢–ï–°–¢: '{query}'")
        print("-" * 50)
        
        results = search_engine.hybrid_search(query, top_k=5)
        
        yc_found = any('YC5194' in result['text'] for result in results if 'YC5194' in query)
        gw_found = any('GW1-59' in result['text'] for result in results if 'GW1-59' in query)
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
        print(f"üéØ –ò—Å–∫–æ–º—ã–π —à—Ç–∞–º–º –Ω–∞–π–¥–µ–Ω: {yc_found or gw_found}")
        
        for i, result in enumerate(results[:3]):
            search_type = result.get('search_type', 'unknown')
            
            print(f"\n{i+1}. [{search_type.upper()}] –°–∫–æ—Ä: {result['final_score']:.3f}")
            print(f"   –§–∞–π–ª: {result['metadata'].get('source_pdf', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å–∫–æ–º—ã—Ö —à—Ç–∞–º–º–æ–≤
            contains_yc = 'YC5194' in result['text']
            contains_gw = 'GW1-59' in result['text'] 
            
            if contains_yc:
                print(f"   ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç YC5194")
            if contains_gw:
                print(f"   ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç GW1-59T")
                
            print(f"   –ü–µ—Ä–≤—ã–µ 150 —Å–∏–º–≤–æ–ª–æ–≤: {result['text'][:150]}...")
            
        print("\n" + "="*60)

def demo_fix():
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    """
    print("üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –ü–û–ò–°–ö–ê YC5194")
    print("=" * 50)
    
    search_engine = ImprovedSearchEngine()
    
    query = "–ö–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ç–∞–º–º–∞ Lysobacter capsici YC5194?"
    print(f"–ó–∞–ø—Ä–æ—Å: {query}")
    
    results = search_engine.hybrid_search(query, top_k=10)
    
    yc_results = [r for r in results if 'YC5194' in r['text']]
    
    print(f"\nüìä –í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
    print(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å YC5194: {len(yc_results)}")
    
    if yc_results:
        print(f"\n‚úÖ –£–°–ü–ï–•! –ù–∞–π–¥–µ–Ω—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for i, result in enumerate(yc_results[:5]):
            print(f"\n{i+1}. –§–∞–π–ª: {result['metadata'].get('source_pdf', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}")
            print(f"   –¢–∏–ø: {result['metadata'].get('chunk_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}")
            print(f"   –°–∫–æ—Ä: {result['final_score']:.3f}")
            print(f"   –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {result['text'][:200]}...")
    else:
        print("‚ùå YC5194 –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω")

if __name__ == "__main__":
    test_improved_search()
    print("\n\n")
    demo_fix() 