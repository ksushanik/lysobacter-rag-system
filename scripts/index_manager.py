#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π
–ü–æ–¥–æ–±–Ω–æ NotebookLM - –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω —Ä–∞–∑, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ —Ä–∞–∑
"""

import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from config import config
from src.lysobacter_rag.pdf_extractor import PDFExtractor
from src.lysobacter_rag.data_processor import DataProcessor
from src.lysobacter_rag.indexer import Indexer
from loguru import logger

class IndexManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏"""
    
    def __init__(self):
        self.storage_dir = config.STORAGE_DIR
        self.index_metadata_file = self.storage_dir / "index_metadata.json"
        self.data_dir = config.DATA_DIR
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
    def get_index_status(self) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Ç–µ–∫—É—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"""
        
        if not self.index_metadata_file.exists():
            return {
                'exists': False,
                'created_at': None,
                'pdf_count': 0,
                'chunk_count': 0,
                'last_updated': None,
                'status': 'not_created'
            }
        
        try:
            with open(self.index_metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –∏–Ω–¥–µ–∫—Å
            chroma_path = Path(config.CHROMA_DB_PATH)
            if not chroma_path.exists():
                return {
                    'exists': False,
                    'status': 'metadata_only',
                    **metadata
                }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞
            pdf_files = list(self.data_dir.glob("*.pdf"))
            current_pdf_count = len(pdf_files)
            
            if current_pdf_count != metadata.get('pdf_count', 0):
                metadata['status'] = 'outdated'
                metadata['current_pdf_count'] = current_pdf_count
            else:
                metadata['status'] = 'ready'
            
            return {
                'exists': True,
                **metadata
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–∞: {e}")
            return {
                'exists': False,
                'status': 'error',
                'error': str(e)
            }
    
    def create_index(self, force_rebuild: bool = False) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏–∑ PDF —Ñ–∞–π–ª–æ–≤
        
        Args:
            force_rebuild: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
            
        Returns:
            bool: True –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
        """
        
        print("üèóÔ∏è –°–û–ó–î–ê–ù–ò–ï –ò–ù–î–ï–ö–°–ê –ó–ù–ê–ù–ò–ô –û –õ–ò–ó–û–ë–ê–ö–¢–ï–†–ò–Ø–•")
        print("=" * 60)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        status = self.get_index_status()
        
        if status['exists'] and status['status'] == 'ready' and not force_rebuild:
            print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∞–∫—Ç—É–∞–ª–µ–Ω")
            print(f"   üìä PDF —Ñ–∞–π–ª–æ–≤: {status['pdf_count']}")
            print(f"   üìö –ß–∞–Ω–∫–æ–≤: {status['chunk_count']}")
            print(f"   üïí –°–æ–∑–¥–∞–Ω: {status['created_at']}")
            return True
        
        # –ù–∞—Ö–æ–¥–∏–º PDF —Ñ–∞–π–ª—ã
        pdf_files = list(self.data_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"‚ùå PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ {self.data_dir}")
            return False
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª–æ–≤: {len(pdf_files)}")
        print(f"üìÇ –ü–∞–ø–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {self.data_dir}")
        print(f"üóÑÔ∏è –ò–Ω–¥–µ–∫—Å –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {config.CHROMA_DB_PATH}")
        
        if force_rebuild:
            print("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞...")
        
        try:
            # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF
            print(f"\nüì§ –®–ê–ì 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF...")
            extractor = PDFExtractor()
            
            all_docs = []
            success_count = 0
            
            for pdf_file in pdf_files:
                print(f"   üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {pdf_file.name}")
                doc = extractor.extract_from_pdf(str(pdf_file))
                
                if doc:
                    all_docs.append(doc)
                    success_count += 1
                    print(f"      ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {doc.total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü, {len(doc.tables)} —Ç–∞–±–ª–∏—Ü")
                else:
                    print(f"      ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å")
            
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:")
            print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {success_count}/{len(pdf_files)}")
            print(f"   üìã –í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_docs)}")
            
            if not all_docs:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ PDF —Ñ–∞–π–ª–æ–≤")
                return False
            
            # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —á–∞–Ω–∫–∏
            print(f"\nüîÑ –®–ê–ì 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            processor = DataProcessor()
            chunks = processor.process_documents(all_docs)
            
            print(f"   üìö –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = processor.get_statistics(chunks)
            print(f"   üìù –¢–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏: {stats['text_chunks']}")
            print(f"   üìä –¢–∞–±–ª–∏—á–Ω—ã–µ —á–∞–Ω–∫–∏: {stats['table_chunks']}")
            print(f"   üìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞: {stats['avg_chunk_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
            print(f"\nüóÉÔ∏è –®–ê–ì 3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if force_rebuild:
                try:
                    indexer = Indexer()
                    indexer.delete_collection()
                    print("   üóëÔ∏è –°—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å —É–¥–∞–ª–µ–Ω")
                except:
                    pass
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
            indexer = Indexer()
            success = indexer.index_chunks(chunks)
            
            if not success:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞")
                return False
            
            # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            print(f"\nüíæ –®–ê–ì 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
            
            metadata = {
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'pdf_count': len(pdf_files),
                'chunk_count': len(chunks),
                'text_chunks': stats['text_chunks'],
                'table_chunks': stats['table_chunks'],
                'sources': stats['sources'],
                'embedding_model': config.EMBEDDING_MODEL,
                'chunk_size': config.CHUNK_SIZE,
                'chunk_overlap': config.CHUNK_OVERLAP
            }
            
            with open(self.index_metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            print(f"   ‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            collection_stats = indexer.get_collection_stats()
            
            print(f"\nüéâ –ò–ù–î–ï–ö–° –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù!")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞:")
            print(f"   üìö –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ –≤ –ë–î: {collection_stats['total_chunks']}")
            print(f"   üìù –¢–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤: {collection_stats['chunk_types'].get('text', 0)}")
            print(f"   üìä –¢–∞–±–ª–∏—á–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {collection_stats['chunk_types'].get('table', 0)}")
            print(f"   üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(collection_stats['sources'])}")
            print(f"   üóÑÔ∏è –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {config.CHROMA_DB_PATH}")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            return False

def main():
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–º"""
    
    import argparse
    
    parser = argparse.ArgumentParser(description="–ú–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π")
    parser.add_argument('action', choices=['status', 'create', 'rebuild'],
                       help='–î–µ–π—Å—Ç–≤–∏–µ —Å –∏–Ω–¥–µ–∫—Å–æ–º')
    parser.add_argument('--force', action='store_true',
                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è')
    
    args = parser.parse_args()
    
    manager = IndexManager()
    
    if args.action == 'status':
        status = manager.get_index_status()
        print("üìä –°–¢–ê–¢–£–° –ò–ù–î–ï–ö–°–ê")
        print("=" * 40)
        
        if status['exists']:
            print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {status['status']}")
            print(f"üìÖ –°–æ–∑–¥–∞–Ω: {status.get('created_at', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            print(f"üìÑ PDF —Ñ–∞–π–ª–æ–≤: {status.get('pdf_count', 0)}")
            print(f"üìö –ß–∞–Ω–∫–æ–≤: {status.get('chunk_count', 0)}")
        else:
            print("‚ùå –ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω")
            print("üí° –°–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å: python index_manager.py create")
    
    elif args.action == 'create':
        manager.create_index(force_rebuild=args.force)
    
    elif args.action == 'rebuild':
        manager.create_index(force_rebuild=True)

if __name__ == "__main__":
    main() 