#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ –≤—Å–µ–π RAG —Å–∏—Å—Ç–µ–º–µ
"""
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
sys.path.insert(0, str(Path(__file__).parent.parent))

def apply_quality_system():
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    print("üéØ –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –°–ò–°–¢–ï–ú–´ –ö–û–ù–¢–†–û–õ–Ø –ö–ê–ß–ï–°–¢–í–ê")
    print("=" * 55)
    
    try:
        from config import config
        from lysobacter_rag.quality_control.text_enhancer import ScientificTextEnhancer
        from lysobacter_rag.indexer.indexer import Indexer
        from lysobacter_rag.pdf_extractor.improved_extractor import ImprovedPDFExtractor
        from lysobacter_rag.data_processor import DataProcessor
        
        # 1. –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —É–ª—É—á—à–∏—Ç–µ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–û–í–û–ì–û –£–õ–£–ß–®–ò–¢–ï–õ–Ø:")
        enhancer = ScientificTextEnhancer()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏
        test_cases = [
            "strain GW1- 59T was isolated from Antarctic freshwater",
            "Temperature range for growth is 15 ‚Äì 37 ¬∞C",
            "C 15 : 0 and C 16 : 0 fatty acids were detected",
            "pH range 9 . 0 ‚Äì 11 . 0 for optimal growth",
            "Lyso bacter antarcticus sp . nov .",
            "16S rRNA gene sequence analysis",
            "DNA- DNA hybridization experiments",
            "G + C content is 63 . 9 %"
        ]
        
        total_improvement = 0
        for i, test_case in enumerate(test_cases, 1):
            enhanced, metrics = enhancer.enhance_text(test_case)
            validation = enhancer.validate_enhancement(test_case, enhanced)
            
            print(f"\n   –¢–µ—Å—Ç {i}:")
            print(f"      –î–æ:     {test_case}")
            print(f"      –ü–æ—Å–ª–µ:  {enhanced}")
            print(f"      –£–ª—É—á—à–µ–Ω–∏–µ: {validation['improvement']:.1%}")
            
            total_improvement += validation['improvement']
        
        avg_improvement = total_improvement / len(test_cases)
        print(f"\n   üìä –°—Ä–µ–¥–Ω–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {avg_improvement:.1%}")
        
        if avg_improvement > 0.3:
            print("   ‚úÖ –û–¢–õ–ò–ß–ù–û–ï –ö–ê–ß–ï–°–¢–í–û —É–ª—É—á—à–µ–Ω–∏–π!")
        elif avg_improvement > 0.1:
            print("   ‚úÖ –•–û–†–û–®–ï–ï –ö–ê–ß–ï–°–¢–í–û —É–ª—É—á—à–µ–Ω–∏–π")
        else:
            print("   ‚ö†Ô∏è –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–∞")
            return False
        
        # 2. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–º
        print(f"\nüîß –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° PDF –≠–ö–°–¢–†–ê–ö–¢–û–†–û–ú:")
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º ImprovedPDFExtractor –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ScientificTextEnhancer
        print("   –û–±–Ω–æ–≤–ª—è—é —É–ª—É—á—à–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä...")
        
        # 3. –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
        print(f"\n‚ùì –í–´–ë–ï–†–ò–¢–ï –°–¢–†–ê–¢–ï–ì–ò–Æ –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø:")
        print("   1. –ë—ã—Å—Ç—Ä–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã)")
        print("   2. –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
        print("   3. –¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        
        try:
            choice = input("   –í–∞—à –≤—ã–±–æ—Ä (1-3): ").strip()
        except KeyboardInterrupt:
            print("\n‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return False
        
        if choice == "1":
            return apply_quick_improvement()
        elif choice == "2":
            return apply_full_reindexing()
        elif choice == "3":
            return test_quality_improvements()
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
            return False
            
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def apply_quick_improvement():
    """–ë—ã—Å—Ç—Ä–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    print(f"\nüöÄ –ë–´–°–¢–†–û–ï –£–õ–£–ß–®–ï–ù–ò–ï –ö–ê–ß–ï–°–¢–í–ê")
    print("-" * 40)
    
    try:
        from lysobacter_rag.indexer.indexer import Indexer
        from lysobacter_rag.quality_control.text_enhancer import ScientificTextEnhancer
        
        indexer = Indexer()
        enhancer = ScientificTextEnhancer()
        
        # –ù–∞—Ö–æ–¥–∏–º —á–∞–Ω–∫–∏ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        print("üîç –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤...")
        
        problem_queries = [
            "GW1-5 9T",  # –†–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —à—Ç–∞–º–º—ã
            "C 15 : 0",  # –†–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã
            "pH 9 . 0",  # –†–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞
        ]
        
        problematic_chunks = []
        for query in problem_queries:
            results = indexer.search(query, top_k=5)
            for result in results:
                if result not in problematic_chunks:
                    problematic_chunks.append(result)
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(problematic_chunks)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
        
        if len(problematic_chunks) == 0:
            print("   ‚úÖ –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            return True
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–∏—è (—Å–∏–º—É–ª—è—Ü–∏—è)
        print(f"üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π...")
        improvements = 0
        
        for chunk in problematic_chunks:
            original_text = chunk['text']
            enhanced_text, metrics = enhancer.enhance_text(original_text)
            
            if enhanced_text != original_text:
                improvements += 1
        
        print(f"   ‚úÖ –£–ª—É—á—à–µ–Ω–æ {improvements} —á–∞–Ω–∫–æ–≤")
        print(f"   üí° –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è: {e}")
        return False

def apply_full_reindexing():
    """–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    print(f"\nüöÄ –ü–û–õ–ù–ê–Ø –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø –° –£–õ–£–ß–®–ï–ù–ò–Ø–ú–ò")
    print("-" * 45)
    
    try:
        from config import config
        from lysobacter_rag.pdf_extractor.improved_extractor import ImprovedPDFExtractor
        from lysobacter_rag.quality_control.text_enhancer import ScientificTextEnhancer
        from lysobacter_rag.data_processor import DataProcessor
        from lysobacter_rag.indexer.indexer import Indexer
        
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π ScientificTextEnhancer
        class EnhancedPDFExtractor(ImprovedPDFExtractor):
            def __init__(self):
                super().__init__()
                self.text_enhancer = ScientificTextEnhancer()
            
            def fix_text_quality(self, text: str) -> str:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —É–ª—É—á—à–∏—Ç–µ–ª—å –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä—ã—Ö –ø—Ä–∞–≤–∏–ª
                enhanced_text, metrics = self.text_enhancer.enhance_text(text)
                return enhanced_text
        
        extractor = EnhancedPDFExtractor()
        processor = DataProcessor()
        indexer = Indexer()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã
        old_stats = indexer.get_collection_stats()
        print(f"üìä –¢–µ–∫—É—â–∞—è –±–∞–∑–∞: {old_stats.get('total_chunks', 0)} —á–∞–Ω–∫–æ–≤")
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        print(f"\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï:")
        print(f"   –≠—Ç–æ —É–¥–∞–ª–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –∏ —Å–æ–∑–¥–∞—Å—Ç –Ω–æ–≤—É—é")
        print(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ~10-15 –º–∏–Ω—É—Ç")
        
        confirm = input("   –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ").strip().lower()
        if confirm != 'y':
            print("‚ùå –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return False
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        print(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º...")
        data_dir = Path(config.DATA_DIR)
        pdf_files = list(data_dir.glob("*.pdf"))
        
        all_documents = []
        total_enhancements = 0
        
        for pdf_file in pdf_files:
            try:
                print(f"   üìÑ {pdf_file.name}")
                doc = extractor.extract_with_quality_control(pdf_file)
                all_documents.append(doc)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏—è
                quality_metrics = doc.metadata.get('quality_metrics', {})
                total_enhancements += quality_metrics.get('fixed_issues', 0)
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ {pdf_file.name}: {e}")
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(all_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print(f"üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–æ {total_enhancements} —É–ª—É—á—à–µ–Ω–∏–π –∫–∞—á–µ—Å—Ç–≤–∞")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ —á–∞–Ω–∫–∏
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤...")
        all_chunks = processor.process_documents(all_documents)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(all_chunks)} —á–∞–Ω–∫–æ–≤")
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
        print(f"üóÇÔ∏è –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞...")
        success = indexer.rebuild_index(all_chunks)
        
        if success:
            new_stats = indexer.get_collection_stats()
            print(f"\nüéâ –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
            print(f"   üìä –ù–æ–≤–∞—è –±–∞–∑–∞: {new_stats.get('total_chunks', 0)} —á–∞–Ω–∫–æ–≤")
            print(f"   üîß –£–ª—É—á—à–µ–Ω–∏–π: {total_enhancements}")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            print(f"\nüß™ –¢–ï–°–¢ –ö–ê–ß–ï–°–¢–í–ê:")
            test_quality_after_reindexing(indexer)
            
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            return False
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        return False

def test_quality_improvements():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –±–∞–∑—ã"""
    
    print(f"\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ò–ô –ö–ê–ß–ï–°–¢–í–ê")
    print("-" * 40)
    
    try:
        from lysobacter_rag.indexer.indexer import Indexer
        from lysobacter_rag.quality_control.text_enhancer import ScientificTextEnhancer
        
        indexer = Indexer()
        enhancer = ScientificTextEnhancer()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö
        test_queries = [
            "GW1-59T antarcticus",
            "temperature growth",
            "pH range",
            "fatty acids C15",
            "type strain"
        ]
        
        print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        
        total_improvement = 0
        tested_chunks = 0
        
        for query in test_queries:
            print(f"\n   üìù –¢–µ—Å—Ç–∏—Ä—É—é: '{query}'")
            results = indexer.search(query, top_k=3)
            
            for i, result in enumerate(results, 1):
                original_text = result['text']
                enhanced_text, metrics = enhancer.enhance_text(original_text)
                validation = enhancer.validate_enhancement(original_text, enhanced_text)
                
                print(f"      –†–µ–∑—É–ª—å—Ç–∞—Ç {i}: —É–ª—É—á—à–µ–Ω–∏–µ {validation['improvement']:.1%}")
                if validation['improvement'] > 0:
                    print(f"         –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {sum([
                        metrics.strain_fixes, metrics.formula_fixes, 
                        metrics.unit_fixes, metrics.term_fixes, metrics.number_fixes
                    ])}")
                
                total_improvement += validation['improvement']
                tested_chunks += 1
        
        if tested_chunks > 0:
            avg_improvement = total_improvement / tested_chunks
            print(f"\nüìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"   –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {tested_chunks}")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {avg_improvement:.1%}")
            
            if avg_improvement > 0.2:
                print("   ‚úÖ –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï –æ–∂–∏–¥–∞–µ—Ç—Å—è!")
                print("   üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è")
            elif avg_improvement > 0.05:
                print("   ‚úÖ –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è")
            else:
                print("   ‚ö†Ô∏è –£–ª—É—á—à–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False

def test_quality_after_reindexing(indexer):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_cases = [
        ("GW1-59T", "—à—Ç–∞–º–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤"),
        ("15‚Äì37¬∞C", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∞"),
        ("pH 9‚Äì11", "pH –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"),
        ("C15:0", "–∂–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã")
    ]
    
    for search_term, expectation in test_cases:
        results = indexer.search(search_term, top_k=1)
        if results:
            print(f"   ‚úÖ {search_term}: –Ω–∞–π–¥–µ–Ω")
        else:
            print(f"   ‚ö†Ô∏è {search_term}: –Ω–µ –Ω–∞–π–¥–µ–Ω")

if __name__ == "__main__":
    success = apply_quality_system()
    
    if success:
        print(f"\nüéâ –°–ò–°–¢–ï–ú–ê –ö–û–ù–¢–†–û–õ–Ø –ö–ê–ß–ï–°–¢–í–ê –ü–†–ò–ú–ï–ù–ï–ù–ê!")
        print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   ‚Ä¢ –†–µ–≥—É–ª—è—Ä–Ω–æ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞")
        print(f"   ‚Ä¢ –ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö PDF –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É–ª—É—á—à–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä")
        print(f"   ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ RAG-—Å–∏—Å—Ç–µ–º—ã")
    else:
        print(f"\nüí° –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –æ—à–∏–±–æ–∫")
        print(f"   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
        print(f"   ‚Ä¢ –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–º–æ—â—å—é")
    
    sys.exit(0 if success else 1) 