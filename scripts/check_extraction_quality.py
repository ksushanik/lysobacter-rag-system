#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from lysobacter_rag.indexer.indexer import Indexer

def check_extraction_quality():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    
    print("üîç –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –¢–ï–ö–°–¢–ê")
    print("=" * 50)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å–µ—Ä
        indexer = Indexer()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = indexer.get_collection_stats()
        print(f"üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats.get('total_chunks', 0)}")
        
        # –ò—â–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏
        test_queries = [
            "GW1-59T",
            "temperature",
            "characteristics", 
            "analysis"
        ]
        
        print("\nüîç –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –¢–ï–ö–°–¢–ê:")
        print("-" * 40)
        
        for query in test_queries:
            print(f"\nüìù –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
            
            results = indexer.search(query, top_k=3)
            
            for i, result in enumerate(results[:2], 1):
                content = result.get('text', '')
                
                print(f"\n   üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç {i}:")
                print(f"   üìã –î–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª–∏—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç
                words = content.split()
                long_words = [word for word in words if len(word) > 20]
                
                if long_words:
                    print(f"   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ ({len(long_words)}):")
                    for word in long_words[:3]:
                        print(f"      ‚Ä¢ {word[:50]}...")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
                no_space_sequences = []
                for i, char in enumerate(content):
                    if i > 0 and char.isupper() and content[i-1].islower():
                        # –í–æ–∑–º–æ–∂–Ω–æ–µ –º–µ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞ –ø—Ä–æ–±–µ–ª–∞
                        start = max(0, i-10)
                        end = min(len(content), i+10)
                        no_space_sequences.append(content[start:end])
                
                if no_space_sequences:
                    print(f"   ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏ –ø—Ä–æ–±–µ–ª–æ–≤ ({len(no_space_sequences[:3])}):")
                    for seq in no_space_sequences[:3]:
                        print(f"      ‚Ä¢ ...{seq}...")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü —Ç–µ–∫—Å—Ç–∞
                print(f"   üìù –û–±—Ä–∞–∑–µ—Ü (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
                print(f"      {content[:200]}...")
                
                if i == 1:
                    print()
        
        print(f"\n{'='*50}")
        print("‚úÖ –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("   ‚Ä¢ –ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ —Å–ª–∏—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç - –≤–∫–ª—é—á–∏—Ç–µ USE_ENHANCED_EXTRACTOR=True –≤ config.py")
        print("   ‚Ä¢ –î–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º")
        print("   ‚Ä¢ –ü—Ä–æ–ø—É—Å–∫–∏ –ø—Ä–æ–±–µ–ª–æ–≤ - —Ç–∏–ø–∏—á–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –ø—Ä–æ—Å—Ç—ã—Ö PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_extraction_quality() 