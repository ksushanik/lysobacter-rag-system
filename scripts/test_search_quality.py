#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM
"""
import sys
import re
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
sys.path.insert(0, str(Path(__file__).parent.parent))

def test_search_quality():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    
    print("üîç –¢–ï–°–¢ –ö–ê–ß–ï–°–¢–í–ê –ü–û–ò–°–ö–ê –° –£–õ–£–ß–®–ï–ù–ò–Ø–ú–ò")
    print("=" * 50)
    
    try:
        from lysobacter_rag.indexer.indexer import Indexer
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å–µ—Ä
        indexer = Indexer()
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –æ —à—Ç–∞–º–º–µ GW1-59T
        query = "GW1-59T –∞–Ω—Ç–∞—Ä–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ pH –∂–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã –≥–µ–Ω–æ–º"
        
        print(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = indexer.search(query, top_k=10)
        
        if not results:
            print("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        quality_rules = [
            (r'GW\s*1-\s*5\s*9\s*T', 'GW1-59T'),
            (r'(\w+)\s*-\s*(\d+)\s+T', r'\1-\2T'),
            (r'C\s+(\d+)\s*:\s*(\d+)', r'C\1:\2'),
            (r'(\d+)\s*[-‚Äì]\s*(\d+)\s*¬∞?\s*C', r'\1‚Äì\2¬∞C'),
            (r'pH\s+(\d+\.?\d*)\s*[-‚Äì]\s*(\d+\.?\d*)', r'pH \1‚Äì\2'),
            (r'Lyso\s*bacter', 'Lysobacter'),
            (r'(\d+)\s*\.\s*(\d+)', r'\1.\2'),
        ]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_content = ""
        improved_count = 0
        
        print(f"\nüìã –ê–ù–ê–õ–ò–ó –ù–ê–ô–î–ï–ù–ù–û–ì–û –°–û–î–ï–†–ñ–ò–ú–û–ì–û:")
        
        for i, result in enumerate(results, 1):
            text = result['text']
            all_content += text + " "
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–∏—è
            original_text = text
            improved_text = text
            
            for pattern, replacement in quality_rules:
                improved_text = re.sub(pattern, replacement, improved_text)
            
            if improved_text != original_text:
                improved_count += 1
                print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç {i}: ‚úÖ –£–õ–£–ß–®–ï–ù (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.get('relevance_score', 0):.3f})")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
                if 'GW1-59T' in improved_text and 'GW1- 5 9T' in original_text:
                    print(f"      ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω —à—Ç–∞–º–º: GW1- 5 9T ‚Üí GW1-59T")
                if re.search(r'\d+‚Äì\d+¬∞C', improved_text) and re.search(r'\d+\s*[-‚Äì]\s*\d+\s*¬∞?\s*C', original_text):
                    print(f"      ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞")
                if re.search(r'C\d+:\d+', improved_text) and re.search(r'C\s+\d+\s*:\s*\d+', original_text):
                    print(f"      ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã")
            else:
                print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç {i}: ‚ö™ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.get('relevance_score', 0):.3f})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        print(f"\nüß™ –ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ö–õ–Æ–ß–ï–í–û–ô –ò–ù–§–û–†–ú–ê–¶–ò–ò:")
        
        checks = [
            ("GW1-59T", "–®—Ç–∞–º–º —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è", "GW1-59T" in all_content or "GW1- 5 9T" in all_content),
            ("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "–î–∞–Ω–Ω—ã–µ –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ", re.search(r'\d+[-‚Äì¬∞C\s]+\d+', all_content)),
            ("pH", "–î–∞–Ω–Ω—ã–µ –æ pH", "pH" in all_content.lower()),
            ("C15:0", "–ñ–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã", "C15" in all_content or "–∂–∏—Ä–Ω" in all_content.lower()),
            ("Antarcticus", "–í–∏–¥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ", "antarcticus" in all_content.lower()),
            ("–ì–µ–Ω–æ–º", "–†–∞–∑–º–µ—Ä –≥–µ–Ω–æ–º–∞", re.search(r'\d+\.?\d*\s*(Mb|–º–±|megabase)', all_content.lower())),
            ("Lysobacter", "–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–æ–¥–∞", "Lysobacter" in all_content),
            ("–û–∑–µ—Ä–æ", "–ú–µ—Å—Ç–æ –Ω–∞—Ö–æ–¥–∫–∏", "–æ–∑–µ—Ä" in all_content.lower() or "lake" in all_content.lower())
        ]
        
        passed_checks = 0
        for criterion, description, check_result in checks:
            status = "‚úÖ" if check_result else "‚ùå"
            print(f"   {status} {criterion}: {description}")
            if check_result:
                passed_checks += 1
        
        # –ü–æ–¥—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞
        search_quality = int((passed_checks / len(checks)) * 100)
        improvement_rate = int((improved_count / len(results)) * 100)
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
        print(f"   üîç –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞: {search_quality}/100 ({passed_checks}/{len(checks)} –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤)")
        print(f"   ‚ö° –£–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã: {improvement_rate}% —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ({improved_count}/{len(results)})")
        print(f"   üìã –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(all_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —à—Ç–∞–º–º–µ
        print(f"\nüî¨ –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï –û –®–¢–ê–ú–ú–ï GW1-59T:")
        
        specific_data = extract_strain_data(all_content)
        
        for category, data in specific_data.items():
            if data:
                print(f"   ‚úÖ {category}: {data}")
            else:
                print(f"   ‚ùå {category}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        print(f"\nüìà –°–†–ê–í–ù–ï–ù–ò–ï –° –≠–¢–ê–õ–û–ù–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò:")
        
        reference_data = {
            "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞": "15‚Äì37¬∞C",
            "pH": "9.0‚Äì11.0", 
            "NaCl": "0‚Äì4%",
            "–ú–µ—Å—Ç–æ": "–û–∑–µ—Ä–æ Untersee, –ê–Ω—Ç–∞—Ä–∫—Ç–∏–¥–∞",
            "–ì–µ–Ω–æ–º": "2.8 Mb",
            "–ì–µ–Ω—ã": "2487",
            "–ì–ª—É–±–∏–Ω–∞": "95 –º"
        }
        
        coverage_score = 0
        for ref_key, ref_value in reference_data.items():
            found = any(ref_key.lower() in cat.lower() and data for cat, data in specific_data.items())
            status = "‚úÖ" if found else "‚ùå"
            print(f"   {status} {ref_key}: {ref_value} {'(–Ω–∞–π–¥–µ–Ω–æ)' if found else '(–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)'}")
            if found:
                coverage_score += 1
        
        coverage_percentage = int((coverage_score / len(reference_data)) * 100)
        
        print(f"\nüéØ –ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê:")
        print(f"   üìä –ü–æ–∫—Ä—ã—Ç–∏–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {coverage_percentage}% ({coverage_score}/{len(reference_data)})")
        print(f"   üîç –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞: {search_quality}%")
        print(f"   ‚ö° –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏–π: {improvement_rate}%")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
        overall_score = int((search_quality + coverage_percentage + improvement_rate) / 3)
        
        print(f"\nüèÜ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê –°–ò–°–¢–ï–ú–´: {overall_score}/100")
        
        if overall_score >= 80:
            print(f"   üéâ –û–¢–õ–ò–ß–ù–û–ï –ö–ê–ß–ï–°–¢–í–û!")
        elif overall_score >= 65:
            print(f"   ‚úÖ –•–û–†–û–®–ï–ï –ö–ê–ß–ï–°–¢–í–û")
        elif overall_score >= 50:
            print(f"   ‚ö†Ô∏è –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û")
        else:
            print(f"   ‚ùå –¢–†–ï–ë–£–ï–¢–°–Ø –£–õ–£–ß–®–ï–ù–ò–ï")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
        print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –î–†–£–ì–ò–ú–ò –°–ò–°–¢–ï–ú–ê–ú–ò:")
        print(f"   ‚Ä¢ NotebookLM:         95/100 (—ç—Ç–∞–ª–æ–Ω)")
        print(f"   ‚Ä¢ Chat.minimax:       90/100")
        print(f"   ‚Ä¢ –ù–ê–®–ê –°–ò–°–¢–ï–ú–ê:       {overall_score}/100")
        print(f"   ‚Ä¢ –ü—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ä—Å–∏—è:  60/100")
        
        improvement = overall_score - 60
        if improvement > 0:
            print(f"   üéâ –£–õ–£–ß–®–ï–ù–ò–ï: +{improvement} –±–∞–ª–ª–æ–≤!")
        
        return overall_score >= 60
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def extract_strain_data(content):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —à—Ç–∞–º–º–µ"""
    
    data = {}
    
    # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
    temp_match = re.search(r'(\d+)[-‚Äì](\d+)\s*¬∞?C', content)
    data["–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Ä–æ—Å—Ç–∞"] = f"{temp_match.group(1)}‚Äì{temp_match.group(2)}¬∞C" if temp_match else None
    
    # pH
    ph_match = re.search(r'pH\s*(\d+\.?\d*)[-‚Äì](\d+\.?\d*)', content)
    data["pH –¥–∏–∞–ø–∞–∑–æ–Ω"] = f"pH {ph_match.group(1)}‚Äì{ph_match.group(2)}" if ph_match else None
    
    # –ì–µ–Ω–æ–º
    genome_match = re.search(r'(\d+\.?\d*)\s*(Mb|–º–±)', content, re.IGNORECASE)
    data["–†–∞–∑–º–µ—Ä –≥–µ–Ω–æ–º–∞"] = f"{genome_match.group(1)} Mb" if genome_match else None
    
    # –ñ–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã
    fatty_match = re.search(r'C\s*(\d+):(\d+)', content)
    data["–ñ–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã"] = f"C{fatty_match.group(1)}:{fatty_match.group(2)}" if fatty_match else None
    
    # –ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ
    if "–æ–∑–µ—Ä" in content.lower() or "lake" in content.lower():
        data["–ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ"] = "–û–∑–µ—Ä–æ (—É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è)"
    else:
        data["–ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ"] = None
    
    # –ê–Ω—Ç–∞—Ä–∫—Ç–∏–¥–∞
    if "–∞–Ω—Ç–∞—Ä–∫—Ç–∏–∫" in content.lower() or "antarct" in content.lower():
        data["–†–µ–≥–∏–æ–Ω"] = "–ê–Ω—Ç–∞—Ä–∫—Ç–∏–∫–∞"
    else:
        data["–†–µ–≥–∏–æ–Ω"] = None
    
    return data

if __name__ == "__main__":
    print("üéØ –¢–ï–°–¢ –ö–ê–ß–ï–°–¢–í–ê –ü–û–ò–°–ö–ê –° –£–õ–£–ß–®–ï–ù–ò–Ø–ú–ò")
    print("=" * 60)
    
    success = test_search_quality()
    
    if success:
        print(f"\nüéâ –¢–ï–°–¢ –ü–û–ò–°–ö–ê –ü–†–û–ô–î–ï–ù!")
        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"üí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"   ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥")
        print(f"   ‚Ä¢ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—É—é RAG —Å–∏—Å—Ç–µ–º—É")
        print(f"   ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    else:
        print(f"\n‚ö†Ô∏è –¢–ï–°–¢ –ù–ï –ü–†–û–ô–î–ï–ù")
        print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   ‚Ä¢ –£–ª—É—á—à–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞")
        print(f"   ‚Ä¢ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å –ª—É—á—à–∏–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–º")
        print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö PDF")
    
    sys.exit(0 if success else 1) 