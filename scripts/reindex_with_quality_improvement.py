#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º —Ç–µ–∫—Å—Ç–∞
"""

import sys
import os
from pathlib import Path
from typing import List, Dict, Any
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from lysobacter_rag.indexer.indexer import Indexer
from lysobacter_rag.pdf_extractor.text_quality_improver import text_quality_improver
from lysobacter_rag.data_processor import DocumentChunk
from loguru import logger
import chromadb
from tqdm import tqdm


def analyze_current_quality():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ì–û –ö–ê–ß–ï–°–¢–í–ê")
    print("=" * 40)
    
    indexer = Indexer()
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö
    test_queries = [
        "YC5194 temperature",
        "Lysobacter capsici",
        "growth conditions",
        "pH temperature range"
    ]
    
    total_quality = 0
    total_samples = 0
    
    for query in test_queries:
        results = indexer.search(query, top_k=3)
        
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}'")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
        
        for i, result in enumerate(results, 1):
            text = result.get('text', '')
            if text:
                quality = text_quality_improver.analyze_text_quality(text)
                total_quality += quality['quality_score']
                total_samples += 1
                
                print(f"   {i}. –ö–∞—á–µ—Å—Ç–≤–æ: {quality['quality_score']}%")
                print(f"      –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.get('relevance_score', 0):.3f}")
                print(f"      –ü—Ä–æ–±–ª–µ–º—ã: {quality.get('issues', [])}")
                print(f"      –¢–µ–∫—Å—Ç: {text[:100]}...")
    
    avg_quality = total_quality / total_samples if total_samples > 0 else 0
    print(f"\nüìä –°–†–ï–î–ù–ò–ô –ü–û–ö–ê–ó–ê–¢–ï–õ–¨ –ö–ê–ß–ï–°–¢–í–ê: {avg_quality:.1f}%")
    
    return avg_quality

def get_all_documents_from_chroma():
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ ChromaDB –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    print("\nüì• –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• –ò–ó –ë–ê–ó–´")
    print("=" * 40)
    
    indexer = Indexer()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        result = indexer.collection.get(
            include=["documents", "metadatas", "ids"]
        )
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(result['ids'])}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç DocumentChunk
        improved_chunks = []
        
        for i, (doc_id, text, metadata) in enumerate(zip(
            result['ids'], 
            result['documents'], 
            result['metadatas']
        )):
            # –£–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞
            improved_text = text_quality_improver.improve_text_quality(text)
            
            # –°–æ–∑–¥–∞—ë–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —á–∞–Ω–∫
            chunk = DocumentChunk(
                chunk_id=metadata.get('chunk_id', doc_id),
                text=improved_text,
                chunk_type=metadata.get('chunk_type', 'text'),
                metadata=metadata or {}
            )
            
            improved_chunks.append(chunk)
            
            if (i + 1) % 1000 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i + 1}/{len(result['ids'])}")
        
        print(f"‚úÖ –£–ª—É—á—à–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(improved_chunks)}")
        return improved_chunks
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return []

def reindex_with_improvements():
    """–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –±–∞–∑—É —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
    
    print("\nüöÄ –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø –° –£–õ–£–ß–®–ï–ù–ò–Ø–ú–ò")
    print("=" * 40)
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    improved_chunks = get_all_documents_from_chroma()
    
    if not improved_chunks:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        return False
    
    # 2. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å–µ—Ä
    indexer = Indexer()
    
    # 3. –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
    print("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
    indexer.delete_collection()
    
    # 4. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
    indexer = Indexer()  # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    
    # 5. –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("üì§ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    success = indexer.index_chunks(improved_chunks, batch_size=50)
    
    if success:
        print("‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        return True
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        return False

def test_improved_quality():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π"""
    
    print("\nüß™ –¢–ï–°–¢ –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ö–ê–ß–ï–°–¢–í–ê")
    print("=" * 40)
    
    indexer = Indexer()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "YC5194 temperature growth",
        "Lysobacter capsici characteristics",
        "strain morphology"
    ]
    
    for query in test_queries:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}'")
        results = indexer.search(query, top_k=3)
        
        for i, result in enumerate(results, 1):
            text = result.get('text', '')
            quality = text_quality_improver.analyze_text_quality(text)
            
            print(f"   {i}. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result.get('relevance_score', 0):.3f}")
            print(f"      –ö–∞—á–µ—Å—Ç–≤–æ: {quality['quality_score']}%")
            print(f"      –¢–µ–∫—Å—Ç: {text[:150]}...")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üîß –£–õ–£–ß–®–ï–ù–ò–ï –ö–ê–ß–ï–°–¢–í–ê RAG –°–ò–°–¢–ï–ú–´")
    print("=" * 70)
    
    # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    quality_before = analyze_current_quality()
    
    # 2. –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    if quality_before < 70:
        print(f"\n‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –Ω–∏–∑–∫–æ–µ ({quality_before:.1f}%)")
        print("üîÑ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏")
        
        confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é? (y/N): ")
        if confirm.lower() != 'y':
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return
    else:
        print(f"\n‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–µ–º–ª–µ–º–æ–µ ({quality_before:.1f}%)")
        confirm = input("–í—Å—ë —Ä–∞–≤–Ω–æ —É–ª—É—á—à–∏—Ç—å? (y/N): ")
        if confirm.lower() != 'y':
            print("‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return
    
    # 3. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
    success = reindex_with_improvements()
    
    if success:
        # 4. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        test_improved_quality()
        
        print("\nüéâ –£–õ–£–ß–®–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º")
        print("‚úÖ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ")
    else:
        print("\n‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –£–õ–£–ß–®–ï–ù–ò–ò")
        print("üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")

if __name__ == "__main__":
    main() 