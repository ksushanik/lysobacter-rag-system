#!/usr/bin/env python3
"""
–ü–û–õ–ù–ê–Ø –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø –í–°–ï–• PDF (88 —Ñ–∞–π–ª–æ–≤)
–í–∫–ª—é—á–∞–µ—Ç YC5194 –∏ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —à—Ç–∞–º–º—ã
"""

import sys
import os
from pathlib import Path
import time
from tqdm import tqdm
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent / "src"))
sys.path.insert(0, str(Path(__file__).parent))

from lysobacter_rag.indexer.indexer import Indexer
from lysobacter_rag.pdf_extractor.advanced_pdf_extractor import AdvancedPDFExtractor
from lysobacter_rag.data_processor import DocumentChunk
from config import config

def full_reindex_all():
    """–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö PDF —Ñ–∞–π–ª–æ–≤"""
    
    print("üß¨ –ü–û–õ–ù–ê–Ø –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Ø –í–°–ï–• PDF –§–ê–ô–õ–û–í")
    print("=" * 60)
    print("üéØ –¶–ï–õ–¨: –í–∫–ª—é—á–∏—Ç—å –í–°–ï 88 —Ñ–∞–π–ª–æ–≤, –≤–∫–ª—é—á–∞—è YC5194")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
    data_dir = Path("data")
    pdf_files = sorted(list(data_dir.glob("*.pdf")))
    
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ YC5194 —Ñ–∞–π–ª –µ—Å—Ç—å
    yc5194_file = data_dir / "Lysobacter capsici_sp_nov_with_antimicro.pdf"
    if yc5194_file.exists():
        print(f"‚úÖ YC5194 —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω: {yc5194_file.name}")
    else:
        print(f"‚ùå YC5194 —Ñ–∞–π–ª –ù–ï –ù–ê–ô–î–ï–ù!")
        return False
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print(f"\nüöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å —É–º–Ω—ã–º —á–∞–Ω–∫–∏–Ω–≥–æ–º
    extractor = AdvancedPDFExtractor(use_smart_chunking=True)
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å–µ—Ä
    indexer = Indexer()
    
    # –ö–†–ò–¢–ò–ß–ù–û: –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    print(f"\nüóëÔ∏è –ü–û–õ–ù–ê–Ø –û–ß–ò–°–¢–ö–ê —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    try:
        indexer.delete_collection()
        print("‚úÖ –°—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∞")
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        indexer = Indexer()  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–Ω–æ–≤–æ
        print("‚úÖ –ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_chunks = 0
    successful_files = 0
    failed_files = []
    processing_stats = {
        'total_files': len(pdf_files),
        'successful_files': 0,
        'failed_files': 0,
        'total_chunks': 0,
        'yc5194_processed': False,
        'chunk_sizes': [],
        'files_processed': []
    }
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –±–∞—Ç—á–∞–º–∏ –ø–æ 10
    print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(pdf_files)} —Ñ–∞–π–ª–æ–≤:")
    
    batch_size = 10
    all_document_chunks = []
    
    for batch_start in range(0, len(pdf_files), batch_size):
        batch_end = min(batch_start + batch_size, len(pdf_files))
        batch_files = pdf_files[batch_start:batch_end]
        
        print(f"\nüì¶ –ë–ê–¢–ß {batch_start//batch_size + 1}: —Ñ–∞–π–ª—ã {batch_start+1}-{batch_end}")
        
        batch_chunks = []
        
        for i, pdf_file in enumerate(batch_files, batch_start + 1):
            try:
                print(f"\n{i:2d}/{len(pdf_files)} üìñ {pdf_file.name}")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ—Ç–º–µ—Ç–∫–∞ –¥–ª—è YC5194
                if "capsici" in pdf_file.name.lower():
                    print(f"   üéØ –í–ê–ñ–ù–û: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª —Å YC5194!")
                
                # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ
                document = extractor.extract_document(pdf_file)
                
                if not document.elements:
                    print(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º: –Ω–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    failed_files.append(pdf_file.name)
                    continue
                    
                print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(document.elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                
                # –®–∞–≥ 2: –£–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥
                chunks = extractor.get_smart_chunks(document)
                
                if not chunks:
                    print(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º: –Ω–µ—Ç —á–∞–Ω–∫–æ–≤")
                    failed_files.append(pdf_file.name)
                    continue
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
                chunk_sizes = [len(chunk['content']) for chunk in chunks]
                avg_size = sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0
                
                print(f"   üß¨ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤, —Å—Ä. —Ä–∞–∑–º–µ—Ä {avg_size:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è YC5194
                if "capsici" in pdf_file.name.lower():
                    yc5194_found = False
                    for chunk in chunks:
                        if "YC5194" in chunk['content']:
                            yc5194_found = True
                            print(f"   üéØ YC5194 –ù–ê–ô–î–ï–ù –≤ —á–∞–Ω–∫–µ! –†–∞–∑–º–µ—Ä: {len(chunk['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
                            break
                    
                    if yc5194_found:
                        processing_stats['yc5194_processed'] = True
                        print(f"   ‚úÖ YC5194 —É—Å–ø–µ—à–Ω–æ –≤–∫–ª—é—á–µ–Ω –≤ –±–∞–∑—É!")
                    else:
                        print(f"   ‚ö†Ô∏è YC5194 –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —á–∞–Ω–∫–∞—Ö - –ø—Ä–æ–≤–µ—Ä–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
                
                # –®–∞–≥ 3: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DocumentChunk
                for j, chunk in enumerate(chunks):
                    doc_chunk = DocumentChunk(
                        chunk_id=f"{pdf_file.stem}_{j}",
                        text=chunk['content'],
                        chunk_type=chunk['metadata'].get('chunk_type', 'text'),
                        metadata=chunk['metadata']
                    )
                    batch_chunks.append(doc_chunk)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                processing_stats['chunk_sizes'].extend(chunk_sizes)
                processing_stats['files_processed'].append({
                    'filename': pdf_file.name,
                    'chunks': len(chunks),
                    'avg_size': avg_size
                })
                
                successful_files += 1
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
                failed_files.append(pdf_file.name)
                continue
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –±–∞—Ç—á
        if batch_chunks:
            print(f"\nüíæ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–∞—Ç—á–∞: {len(batch_chunks)} —á–∞–Ω–∫–æ–≤...")
            try:
                success = indexer.index_chunks(batch_chunks)
                if success:
                    total_chunks += len(batch_chunks)
                    all_document_chunks.extend(batch_chunks)
                    print(f"   ‚úÖ –ë–∞—Ç—á –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω: {len(batch_chunks)} —á–∞–Ω–∫–æ–≤")
                else:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –±–∞—Ç—á–∞")
            except Exception as e:
                print(f"   ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    processing_stats['successful_files'] = successful_files
    processing_stats['failed_files'] = len(failed_files)
    processing_stats['total_chunks'] = total_chunks
    
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful_files}/{len(pdf_files)} —Ñ–∞–π–ª–æ–≤")
    print(f"   üíæ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
    print(f"   üéØ YC5194 –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {'‚úÖ –î–ê' if processing_stats['yc5194_processed'] else '‚ùå –ù–ï–¢'}")
    
    if processing_stats['chunk_sizes']:
        avg_chunk_size = sum(processing_stats['chunk_sizes']) / len(processing_stats['chunk_sizes'])
        print(f"   üìè –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {avg_chunk_size:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    
    if failed_files:
        print(f"   ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã: {len(failed_files)}")
        for file in failed_files[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"      - {file}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    print(f"\nüîç –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê:")
    
    stats = indexer.get_collection_stats()
    final_chunks = stats.get('total_chunks', 0)
    print(f"   üì¶ –ß–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ: {final_chunks}")
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –Ω–∞ YC5194
    print(f"\nüß™ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢ –ù–ê YC5194:")
    try:
        yc_results = indexer.search("Lysobacter capsici YC5194", top_k=5)
        if yc_results:
            best_relevance = yc_results[0]['relevance_score']
            print(f"   ‚úÖ YC5194 –ù–ê–ô–î–ï–ù! –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_relevance:.3f}")
            print(f"   üìù –ü–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤: {yc_results[0]['text'][:100]}...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for i, result in enumerate(yc_results[:3]):
                if "YC5194" in result['text']:
                    print(f"   üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}: –°–û–î–ï–†–ñ–ò–¢ YC5194 (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å {result['relevance_score']:.3f})")
                else:
                    print(f"   ‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}: –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç YC5194 (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å {result['relevance_score']:.3f})")
            
            success = True
        else:
            print(f"   ‚ùå YC5194 –ù–ï –ù–ê–ô–î–ï–ù –í –ë–ê–ó–ï!")
            success = False
            
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ YC5194: {e}")
        success = False
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_file = "full_reindex_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(processing_stats, f, ensure_ascii=False, indent=2)
    print(f"\nüìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
    
    return success

if __name__ == "__main__":
    try:
        print("üöÄ –ù–ê–ß–ò–ù–ê–Æ –ü–û–õ–ù–£–Æ –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Æ –í–°–ï–• PDF...")
        success = full_reindex_all()
        
        if success:
            print(f"\nüéâ –£–°–ü–ï–•: –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"   YC5194 —Ç–µ–ø–µ—Ä—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ")
        else:
            print(f"\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´: –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
        
        exit(0 if success else 1)
        
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        exit(1) 