"""
–ú–æ–¥—É–ª—å RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM
"""

from typing import List, Dict, Any, Optional
from loguru import logger
import openai
from openai import OpenAI

from config import config
from ..indexer import Indexer
from .comparative_analyzer import ComparativeAnalyzer


class RAGPipeline:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è RAG-–ø—Ä–æ—Ü–µ—Å—Å–∞: –ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        if not config.OPENAI_API_KEY:
            raise ValueError("API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENROUTER_API_KEY –∏–ª–∏ OPENAI_API_KEY")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç (—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenRouter)
        if hasattr(config, 'OPENROUTER_API_KEY') and config.OPENROUTER_API_KEY:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenRouter
            self.openai_client = OpenAI(
                api_key=config.OPENROUTER_API_KEY,
                base_url=config.OPENROUTER_BASE_URL
            )
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–ª–∏–µ–Ω—Ç OpenRouter")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OpenAI
            self.openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–ª–∏–µ–Ω—Ç OpenAI")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.indexer = Indexer()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        self.comparative_analyzer = ComparativeAnalyzer()
        
        logger.info("RAG-–ø–∞–π–ø–ª–∞–π–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
    
    def ask_question(self, query: str, top_k: int = None, include_sources: bool = True) -> Dict[str, Any]:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É—è RAG-–ø–æ–¥—Ö–æ–¥
        
        Args:
            query (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            include_sources (bool): –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –æ—Ç–≤–µ—Ç
            
        Returns:
            Dict[str, Any]: –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if top_k is None:
            top_k = config.RAG_TOP_K
        
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–æ–ø—Ä–æ—Å: '{query[:100]}...'")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–º
            if self._is_comparative_query(query):
                logger.info("–û–ø—Ä–µ–¥–µ–ª–µ–Ω —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                return self._handle_comparative_query(query, top_k)
            
            # –®–∞–≥ 1: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            relevant_chunks = self.indexer.hybrid_search(query, top_k=top_k)
            
            if not relevant_chunks:
                return {
                    'answer': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.",
                    'sources': [],
                    'confidence': 0.0,
                    'query': query
                }
            
            # –®–∞–≥ 2: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM
            context = self._build_context(relevant_chunks)
            
            # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM
            answer = self._generate_answer(query, context)
            
            # –®–∞–≥ 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            sources = self._extract_sources(relevant_chunks) if include_sources else []
            
            # –®–∞–≥ 5: –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ
            confidence = self._calculate_confidence(relevant_chunks)
            
            result = {
                'answer': answer,
                'sources': sources,
                'confidence': confidence,
                'query': query,
                'num_sources_used': len(relevant_chunks)
            }
            
            logger.info(f"–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}")
            return {
                'answer': f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}",
                'sources': [],
                'confidence': 0.0,
                'query': query
            }
    
    def _build_context(self, relevant_chunks: List[Dict[str, Any]]) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            str: –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        """
        context_parts = []
        
        for i, chunk in enumerate(relevant_chunks, 1):
            metadata = chunk['metadata']
            text = chunk['text']
            relevance = chunk.get('relevance_score', 0)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_header = f"[–ò–°–¢–û–ß–ù–ò–ö {i}]"
            source_info = f"–î–æ–∫—É–º–µ–Ω—Ç: {metadata.get('source_pdf', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}"
            
            if metadata.get('page_number'):
                source_info += f", –°—Ç—Ä–∞–Ω–∏—Ü–∞: {metadata['page_number']}"
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if metadata.get('chunk_type') == 'table':
                source_info += " [–¢–ê–ë–õ–ò–¶–ê]"
                if metadata.get('table_shape'):
                    source_info += f", –†–∞–∑–º–µ—Ä: {metadata['table_shape']}"
                if metadata.get('extraction_method'):
                    source_info += f", –ú–µ—Ç–æ–¥: {metadata['extraction_method']}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä –¥–ª—è —Ç–∞–±–ª–∏—Ü
                text = f"üìä –¢–ê–ë–õ–ò–ß–ù–´–ï –î–ê–ù–ù–´–ï:\n{text}"
                
            elif metadata.get('original_table_title'):
                source_info += f", –¢–∞–±–ª–∏—Ü–∞: {metadata['original_table_title']}"
            
            source_info += f", –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance:.2f}"
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
            if metadata.get('advanced_extractor'):
                source_info += " [–£–õ–£–ß–®–ï–ù–ù–û–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–ï]"
            
            context_part = f"{source_header}\n{source_info}\n\n–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{text}\n"
            context_parts.append(context_part)
        
        return "\n" + "="*80 + "\n".join(context_parts) + "="*80 + "\n"
    
    def _generate_answer(self, query: str, context: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é OpenAI API
        
        Args:
            query (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context (str): –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            
        Returns:
            str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        system_prompt = """–í—ã - —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –º–∏–∫—Ä–æ–±–∏–æ–ª–æ–≥–∏–∏, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏—è–º. 
        –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π.

        –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
        1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ
        2. –û—Ç–≤–µ—á–∞–π—Ç–µ –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏—Ç–µ
        4. –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [–ò—Å—Ç–æ—á–Ω–∏–∫ X]
        5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞—É—á–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é, –Ω–æ –æ–±—ä—è—Å–Ω—è–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è
        6. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ç–∞–±–ª–∏—Ü, –¥–µ—Ç–∞–ª—å–Ω–æ —Ä–∞–∑–±–µ—Ä–∏—Ç–µ —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        7. –ë—É–¥—å—Ç–µ —Ç–æ—á–Ω—ã –∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã –≤ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        8. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π—Ç–µ –æ—Ç–≤–µ—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏

        –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
        ## –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        [–∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å]
        
        ## –î–ï–¢–ê–õ–ò
        [–ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤]
        
        ## –ò–°–¢–û–ß–ù–ò–ö–ò
        [—É–∫–∞–∑–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤]

        –í–°–ï–ì–î–ê –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."""
        
        user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π –æ –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏—è—Ö:
        {context}
        
        –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}
        
        –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞—è –∏—Å—Ç–æ—á–Ω–∏–∫–∏."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=config.RAG_TEMPERATURE,
                max_tokens=1500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
    
    def _extract_sources(self, relevant_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            List[Dict[str, Any]]: –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        sources = []
        
        for i, chunk in enumerate(relevant_chunks, 1):
            metadata = chunk['metadata']
            
            source = {
                'source_id': i,
                'document': metadata.get('source_pdf', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω'),
                'page_number': metadata.get('page_number', ''),
                'chunk_type': metadata.get('chunk_type', ''),
                'relevance_score': chunk.get('relevance_score', 0)
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–∞–±–ª–∏—Ü
            if metadata.get('chunk_type') == 'table':
                source.update({
                    'table_title': metadata.get('original_table_title', ''),
                    'table_description': metadata.get('table_description', ''),
                    'confidence_score': metadata.get('confidence_score', '')
                })
            
            sources.append(source)
        
        return sources
    
    def _calculate_confidence(self, relevant_chunks: List[Dict[str, Any]]) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            float: –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
        """
        if not relevant_chunks:
            return 0.0
        
        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω—é—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —á–∞–Ω–∫–æ–≤
        relevance_scores = [chunk.get('relevance_score', 0) for chunk in relevant_chunks]
        avg_relevance = sum(relevance_scores) / len(relevance_scores)
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        quantity_bonus = min(len(relevant_chunks) / 5, 0.2)
        
        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ–Ω–∏ –æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã)
        table_bonus = 0.1 if any(c['metadata'].get('chunk_type') == 'table' for c in relevant_chunks) else 0
        
        confidence = min(avg_relevance + quantity_bonus + table_bonus, 1.0)
        return round(confidence, 3)
    
    def ask_multiple_questions(self, questions: List[str]) -> List[Dict[str, Any]]:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–¥—Ä—è–¥
        
        Args:
            questions (List[str]): –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤
            
        Returns:
            List[Dict[str, Any]]: –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤
        """
        results = []
        
        for i, question in enumerate(questions, 1):
            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–æ–ø—Ä–æ—Å {i}/{len(questions)}")
            result = self.ask_question(question)
            results.append(result)
        
        return results
    
    def search_tables_only(self, query: str, top_k: int = 3) -> Dict[str, Any]:
        """
        –ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –≤ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
        """
        # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –≤ —Ç–∞–±–ª–∏—á–Ω—ã—Ö —á–∞–Ω–∫–∞—Ö
        table_chunks = self.indexer.search(query, top_k=top_k, chunk_type="table")
        
        if not table_chunks:
            return {
                'answer': "–í —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.",
                'tables': [],
                'query': query
            }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        context = self._build_context(table_chunks)
        answer = self._generate_answer(query, context)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–∞—Ö
        tables_info = []
        for chunk in table_chunks:
            metadata = chunk['metadata']
            table_info = {
                'document': metadata.get('source_pdf', ''),
                'page_number': metadata.get('page_number', ''),
                'title': metadata.get('original_table_title', ''),
                'description': metadata.get('table_description', ''),
                'shape': metadata.get('table_shape', ''),
                'relevance_score': chunk.get('relevance_score', 0)
            }
            tables_info.append(table_info)
        
        return {
            'answer': answer,
            'tables': tables_info,
            'query': query,
            'num_tables_found': len(table_chunks)
        }
    
    def get_pipeline_stats(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞
        
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        indexer_stats = self.indexer.get_collection_stats()
        
        pipeline_stats = {
            'model_used': config.OPENAI_MODEL,
            'embedding_model': config.EMBEDDING_MODEL,
            'top_k_default': config.RAG_TOP_K,
            'temperature': config.RAG_TEMPERATURE,
            **indexer_stats
        }
        
        return pipeline_stats
    
    def _is_comparative_query(self, query: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–º"""
        comparative_keywords = [
            '—Å—Ä–∞–≤–Ω–∏', '—Å—Ä–∞–≤–Ω–∏—Ç–µ', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ', '—Ä–∞–∑–ª–∏—á–∏—è', '–æ—Ç–ª–∏—á–∏—è', '—Ä–∞–∑–Ω–æ—Å—Ç–∏',
            'compare', 'comparison', 'differences', 'distinguish', 'contrast',
            '–º–µ–∂–¥—É', 'among', '—Ä–∞–∑–ª–∏—á–Ω—ã—Ö', 'different', 'multiple', '–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω',
            '–æ–±—â–∏–µ —á–µ—Ä—Ç—ã', 'common features', '–æ–±—â–Ω–æ—Å—Ç—å', 'similarity',
            '—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö', 'characteristics of different'
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in comparative_keywords)
    
    def _handle_comparative_query(self, query: str, top_k: int) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–¥–∞—Ö
        extended_top_k = max(top_k * 3, 30)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–¥–æ–≤
        expanded_query = self._expand_comparative_query(query)
        
        # –ü–æ–∏—Å–∫ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        relevant_chunks = self.indexer.hybrid_search(expanded_query, top_k=extended_top_k)
        
        if not relevant_chunks:
            return {
                'answer': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.",
                'sources': [],
                'confidence': 0.0,
                'query': query,
                'analysis_type': 'comparative'
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self._build_context(relevant_chunks)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        comparative_report = self.comparative_analyzer.analyze_comparative_query(context, query)
        
        # –ï—Å–ª–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—à–µ–ª –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if comparative_report.species_count > 0:
            answer = comparative_report.formatted_response
            confidence = min(0.8, 0.3 + (comparative_report.species_count * 0.1))
        else:
            # Fallback: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            answer = self._generate_comparative_answer(query, context)
            confidence = self._calculate_confidence(relevant_chunks)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        sources = self._extract_sources(relevant_chunks)
        
        return {
            'answer': answer,
            'sources': sources,
            'confidence': confidence,
            'query': query,
            'analysis_type': 'comparative',
            'species_analyzed': comparative_report.species_count,
            'comparative_features': comparative_report.compared_characteristics,
            'num_sources_used': len(relevant_chunks)
        }
    
    def _expand_comparative_query(self, query: str) -> str:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞"""
        base_terms = ['Lysobacter', '–ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä', '—à—Ç–∞–º–º', 'strain', '–≤–∏–¥', 'species']
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ä–º–∏–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if '–º–æ—Ä—Ñ–æ–ª–æ–≥' in query.lower() or 'morpholog' in query.lower():
            base_terms.extend(['–º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è', '—Ñ–æ—Ä–º–∞', '—Ä–∞–∑–º–µ—Ä', '–∫–ª–µ—Ç–∫–∞', '–∫–æ–ª–æ–Ω–∏'])
        elif '—Ñ–∏–∑–∏–æ–ª–æ–≥' in query.lower() or 'physiol' in query.lower():
            base_terms.extend(['—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', 'pH', '—Ä–æ—Å—Ç', '—É—Å–ª–æ–≤–∏—è'])
        elif '–±–∏–æ—Ö–∏–º' in query.lower() or 'biochem' in query.lower():
            base_terms.extend(['—Ñ–µ—Ä–º–µ–Ω—Ç', '–∫–∞—Ç–∞–ª–∞–∑–∞', '–æ–∫—Å–∏–¥–∞–∑–∞', '–º–µ—Ç–∞–±–æ–ª–∏–∑–º'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        base_terms.extend(['—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏', '—Å–≤–æ–π—Å—Ç–≤–∞', '–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏'])
        
        expanded_query = f"{query} {' '.join(base_terms[:10])}"  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return expanded_query
    
    def _generate_comparative_answer(self, query: str, context: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º"""
        system_prompt = """–í—ã - —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –º–∏–∫—Ä–æ–±–∏–æ–ª–æ–≥–∏–∏, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π.
        –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–≤–æ–¥–∏—Ç—å –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∏–¥–æ–≤ Lysobacter –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê –î–õ–Ø –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:
        1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ
        2. –ò–©–ò–¢–ï –∏ –ò–ó–í–õ–ï–ö–ê–ô–¢–ï –¥–∞–Ω–Ω—ã–µ –æ –í–°–ï–• —É–ø–æ–º—è–Ω—É—Ç—ã—Ö –≤–∏–¥–∞—Ö Lysobacter
        3. –°–†–ê–í–ù–ò–í–ê–ô–¢–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–µ–∂–¥—É –≤–∏–¥–∞–º–∏, –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Ç–µ—Å—å –æ–¥–Ω–∏–º –≤–∏–¥–æ–º
        4. –°–æ–∑–¥–∞–≤–∞–π—Ç–µ –¢–ê–ë–õ–ò–¶–´ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–≥–¥–∞ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ
        5. –í—ã–¥–µ–ª—è–π—Ç–µ –û–ë–©–ò–ï –ß–ï–†–¢–´ –∏ –†–ê–ó–õ–ò–ß–ò–Ø –º–µ–∂–¥—É –≤–∏–¥–∞–º–∏
        6. –£–∫–∞–∑—ã–≤–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ß–ò–°–õ–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï (—Ä–∞–∑–º–µ—Ä—ã, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã, pH)
        7. –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ [–ò—Å—Ç–æ—á–Ω–∏–∫ X]

        –°–¢–†–£–ö–¢–£–†–ê –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ì–û –û–¢–í–ï–¢–ê:
        ## –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó [–Ω–∞–∑–≤–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫]
        
        ### üîÑ –û–ë–©–ò–ï –ß–ï–†–¢–´ –†–û–î–ê LYSOBACTER:
        [—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –æ–±—â–∏–µ –¥–ª—è –≤—Å–µ—Ö/–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –≤–∏–¥–æ–≤]
        
        ### üîç –í–ò–î–û–í–´–ï –†–ê–ó–õ–ò–ß–ò–Ø:
        [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –≤–∏–¥–∞–º–∏ —Å –¥–∞–Ω–Ω—ã–º–∏]
        
        ### üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê:
        [—Ç–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ]
        
        ### üí° –í–´–í–û–î–´:
        [–æ–±–æ–±—â–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–∏–π –∏ –∏—Ö —Ç–∞–∫—Å–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ]

        –ù–ï –ì–û–í–û–†–ò–¢–ï —á—Ç–æ "–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ" - –ò–ó–í–õ–ï–ö–ê–ô–¢–ï –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–∞—Ö!"""
        
        user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π –æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∏–¥–∞—Ö –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π:
        {context}
        
        –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {query}
        
        –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –≤—Å–µ—Ö –≤–∏–¥–æ–≤ Lysobacter, —É–ø–æ–º—è–Ω—É—Ç—ã—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. 
        –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                max_tokens=4000   # –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    try:
        rag = RAGPipeline()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        test_questions = [
            "–ö–∞–∫–∏–µ —Ñ–µ–Ω–æ—Ç–∏–ø–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ—Ç–ª–∏—á–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —à—Ç–∞–º–º—ã –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∞?",
            "–ö–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π?",
            "–í –∫–∞–∫–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö —Ä–∞—Å—Ç—É—Ç –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–∏?"
        ]
        
        for question in test_questions:
            print(f"\nü§î –í–æ–ø—Ä–æ—Å: {question}")
            print("="*80)
            
            result = rag.ask_question(question)
            
            print(f"üí¨ –û—Ç–≤–µ—Ç: {result['answer']}")
            print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2f}")
            print(f"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {result['num_sources_used']}")
            
            if result['sources']:
                print("\nüìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
                for source in result['sources']:
                    print(f"  - {source['document']} (—Å—Ç—Ä. {source['page_number']}, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source['relevance_score']:.2f})")
            
            print("\n" + "="*80)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = rag.get_pipeline_stats()
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω OpenAI API –∫–ª—é—á –∏ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã.") 