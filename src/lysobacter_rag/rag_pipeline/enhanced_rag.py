"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ª–∏–∑–æ–±–∞–∫—Ç–µ—Ä–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
"""

from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass
import openai
from openai import OpenAI

from config import config
from ..indexer import Indexer
from .enhanced_prompts import EnhancedPromptSystem, QueryType
from .context_synthesizer import ContextSynthesizer
from .notebooklm_prompts import NotebookLMPrompts
from .fact_checker import FactChecker

logger = logging.getLogger(__name__)

@dataclass
class EnhancedRAGResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã"""
    answer: str
    sources: List[Dict[str, Any]]
    confidence: float
    query: str
    query_type: str
    num_sources_used: int
    metadata: Dict[str, Any]

class EnhancedRAGPipeline:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ —Å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
    
    def __init__(self, use_notebooklm_style: bool = True):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        if not config.OPENAI_API_KEY:
            raise ValueError("API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENROUTER_API_KEY –∏–ª–∏ OPENAI_API_KEY")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç
        if hasattr(config, 'OPENROUTER_API_KEY') and config.OPENROUTER_API_KEY:
            self.openai_client = OpenAI(
                api_key=config.OPENROUTER_API_KEY,
                base_url=config.OPENROUTER_BASE_URL
            )
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–ª–∏–µ–Ω—Ç OpenRouter –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG")
        else:
            self.openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.indexer = Indexer()
        self.prompt_system = EnhancedPromptSystem()
        self.fact_checker = FactChecker()
        self.use_notebooklm_style = use_notebooklm_style
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º NotebookLM –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
        if self.use_notebooklm_style:
            self.context_synthesizer = ContextSynthesizer()
            logger.info("–í–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º NotebookLM –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        logger.info("–£–ª—É—á—à–µ–Ω–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    
    def ask_question(
        self, 
        query: str, 
        top_k: int = None, 
        query_type: Optional[QueryType] = None,
        prioritize_tables: bool = True,
        use_notebooklm_style: Optional[bool] = None
    ) -> EnhancedRAGResult:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            query (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            query_type (Optional[QueryType]): –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞ (–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            prioritize_tables (bool): –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            use_notebooklm_style (Optional[bool]): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∏–ª—å NotebookLM
            
        Returns:
            EnhancedRAGResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        if top_k is None:
            top_k = config.RAG_TOP_K
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞
        notebooklm_mode = use_notebooklm_style if use_notebooklm_style is not None else self.use_notebooklm_style
        
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{query[:100]}...' (NotebookLM: {notebooklm_mode})")
        
        try:
            # –®–∞–≥ 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
            if query_type is None:
                query_type = self.prompt_system.detect_query_type(query)
            
            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_type.value}")
            
            # –®–∞–≥ 2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if query_type == QueryType.STRAIN_ANALYSIS:
                # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —à—Ç–∞–º–º–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                strain_name = self._extract_strain_name(query)
                if strain_name:
                    logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ —à—Ç–∞–º–º–∞: {strain_name}")
                    relevant_chunks = self._enhanced_strain_search(query, strain_name)
                else:
                    relevant_chunks = self.indexer.search(query, top_k=top_k * 2)
            else:
                relevant_chunks = self.indexer.search(query, top_k=top_k)
            
            if not relevant_chunks:
                return EnhancedRAGResult(
                    answer="–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.",
                    sources=[],
                    confidence=0.0,
                    query=query,
                    query_type=query_type.value,
                    num_sources_used=0,
                    metadata={}
                )
            
            # –®–∞–≥ 3: –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if prioritize_tables:
                relevant_chunks = self._prioritize_structured_data(relevant_chunks)
            
            # –®–∞–≥ 4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if notebooklm_mode and hasattr(self, 'context_synthesizer'):
                # NotebookLM —Å—Ç–∏–ª—å - —Å–∏–Ω—Ç–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                context = self._build_notebooklm_context(relevant_chunks, query)
                formatted_prompt = NotebookLMPrompts.format_enhanced_prompt(
                    query=query, 
                    raw_context=context, 
                    strain_name=self._extract_strain_name(query)
                )
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å—Ç–∏–ª—å
                context, table_metadata = self._build_enhanced_context(relevant_chunks)
                
                # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü
                if table_metadata:
                    context = self.prompt_system.enhance_context_for_tables(context, table_metadata)
                
                formatted_prompt = self.prompt_system.format_prompt(query, context, query_type)
            
            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            answer = self._generate_enhanced_answer(formatted_prompt)
            
            # –®–∞–≥ 5.5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —à—Ç–∞–º–º–æ–≤)
            if query_type == QueryType.STRAIN_ANALYSIS:
                answer = self._validate_facts_in_answer(answer, relevant_chunks, query)
            
            # –®–∞–≥ 6: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            sources = self._extract_enhanced_sources(relevant_chunks)
            confidence = self._calculate_enhanced_confidence(relevant_chunks, query_type)
            
            # –®–∞–≥ 7: –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            metadata = {
                'prompt_type': query_type.value,
                'notebooklm_mode': notebooklm_mode,
                'context_length': len(context) if isinstance(context, str) else len(str(context)),
                'num_sources': len(relevant_chunks)
            }
            
            result = EnhancedRAGResult(
                answer=answer,
                sources=sources,
                confidence=confidence,
                query=query,
                query_type=query_type.value,
                num_sources_used=len(relevant_chunks),
                metadata=metadata
            )
            
            logger.info(f"–£–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω (—Ç–∏–ø: {query_type.value}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º–µ: {str(e)}")
            return EnhancedRAGResult(
                answer=f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}",
                sources=[],
                confidence=0.0,
                query=query,
                query_type=query_type.value if query_type else "unknown",
                num_sources_used=0,
                metadata={}
            )
    
    def _build_notebooklm_context(self, relevant_chunks: List[Dict[str, Any]], query: str) -> str:
        """
        –°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Å—Ç–∏–ª–µ NotebookLM
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            query (str): –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            str: –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
        text_chunks = []
        for chunk in relevant_chunks:
            content = chunk.get('text', '')
            source_info = f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {chunk.get('id', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}]"
            text_chunks.append(f"{content}\n{source_info}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        synthesized_context = self.context_synthesizer.synthesize_for_notebooklm_style(
            text_chunks=text_chunks,
            query=query
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã
        full_context = synthesized_context + "\n\n" + "–ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:\n" + "\n\n".join(text_chunks[:5])
        
        return full_context
    
    def _prioritize_structured_data(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–∞–±–ª–∏—Ü—ã)
        
        Args:
            chunks (List[Dict[str, Any]]): –ò—Å—Ö–æ–¥–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            List[Dict[str, Any]]: –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
        """
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ç–∞–±–ª–∏—Ü—ã –∏ —Ç–µ–∫—Å—Ç
        tables = [c for c in chunks if c['metadata'].get('chunk_type') == 'table']
        texts = [c for c in chunks if c['metadata'].get('chunk_type') != 'table']
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
        tables.sort(key=lambda x: (
            x.get('relevance_score', 0),
            x['metadata'].get('likely_differential_table', False),
            x['metadata'].get('differential_score', 0)
        ), reverse=True)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –ø–µ—Ä–≤—ã–º–∏, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç
        return tables + texts
    
    def _build_enhanced_context(self, relevant_chunks: List[Dict[str, Any]]) -> tuple[str, List[Dict[str, Any]]]:
        """
        –°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            tuple[str, List[Dict[str, Any]]]: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü
        """
        context_parts = []
        table_metadata = []
        
        for i, chunk in enumerate(relevant_chunks, 1):
            metadata = chunk['metadata']
            text = chunk['text']
            relevance = chunk.get('relevance_score', 0)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_header = f"[–ò–°–¢–û–ß–ù–ò–ö {i}]"
            source_info = f"–î–æ–∫—É–º–µ–Ω—Ç: {metadata.get('source_pdf', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}"
            
            if metadata.get('page_number'):
                source_info += f", –°—Ç—Ä–∞–Ω–∏—Ü–∞: {metadata['page_number']}"
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü
            if metadata.get('chunk_type') == 'table':
                source_info += " [–¢–ê–ë–õ–ò–¶–ê]"
                if metadata.get('original_table_title'):
                    source_info += f", –ó–∞–≥–æ–ª–æ–≤–æ–∫: {metadata['original_table_title']}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü
                table_metadata.append(metadata)
            
            source_info += f", –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance:.2f}"
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            if metadata.get('element_type') == 'table':
                content_header = "–¢–ê–ë–õ–ò–ß–ù–´–ï –î–ê–ù–ù–´–ï:"
            elif metadata.get('element_type') == 'title':
                content_header = "–ó–ê–ì–û–õ–û–í–û–ö:"
            else:
                content_header = "–°–û–î–ï–†–ñ–ê–ù–ò–ï:"
            
            context_part = f"{source_header}\n{source_info}\n\n{content_header}\n{text}\n"
            context_parts.append(context_part)
        
        context = "\n" + "="*80 + "\n".join(context_parts) + "="*80 + "\n"
        return context, table_metadata
    
    def _generate_enhanced_answer(self, formatted_prompt: Dict[str, str]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        
        Args:
            formatted_prompt (Dict[str, str]): –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            
        Returns:
            str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        try:
            messages = [
                {"role": "system", "content": formatted_prompt['system']},
                {"role": "user", "content": formatted_prompt['user']}
            ]
            
            response = self.openai_client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=messages,
                temperature=config.RAG_TEMPERATURE,
                max_tokens=8000  # –°—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Å—Ç–∏–ª–µ NotebookLM
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
    
    def _extract_enhanced_sources(self, relevant_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            List[Dict[str, Any]]: –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        sources = []
        
        for i, chunk in enumerate(relevant_chunks, 1):
            metadata = chunk['metadata']
            
            source = {
                'id': i,
                'document': metadata.get('source_pdf', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω'),
                'page': metadata.get('page_number'),
                'type': metadata.get('element_type', 'text'),
                'relevance_score': chunk.get('relevance_score', 0),
                'text_preview': chunk['text'][:200] + "..." if len(chunk['text']) > 200 else chunk['text']
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü
            if metadata.get('chunk_type') == 'table':
                source.update({
                    'table_title': metadata.get('original_table_title'),
                    'is_differential_table': metadata.get('likely_differential_table', False),
                    'differential_score': metadata.get('differential_score', 0)
                })
            
            sources.append(source)
        
        return sources
    
    def _calculate_enhanced_confidence(self, relevant_chunks: List[Dict[str, Any]], query_type: QueryType) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        Args:
            relevant_chunks (List[Dict[str, Any]]): –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            query_type (QueryType): –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            float: –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        """
        if not relevant_chunks:
            return 0.0
        
        # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        avg_relevance = sum(chunk.get('relevance_score', 0) for chunk in relevant_chunks) / len(relevant_chunks)
        confidence = avg_relevance
        
        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        table_chunks = [c for c in relevant_chunks if c['metadata'].get('chunk_type') == 'table']
        if table_chunks and query_type in [QueryType.STRAIN_ANALYSIS, QueryType.COMPARATIVE_ANALYSIS, QueryType.TABLE_INTERPRETATION]:
            confidence += 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
        differential_tables = [c for c in table_chunks if c['metadata'].get('likely_differential_table')]
        if differential_tables:
            confidence += 0.1
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if len(relevant_chunks) < 3:
            confidence *= 0.8
        
        return min(confidence, 1.0)
    
    def get_query_types(self) -> List[Dict[str, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤
        
        Returns:
            List[Dict[str, str]]: –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        return self.prompt_system.get_available_query_types()
    
    def get_pipeline_stats(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–ª—É—á—à–µ–Ω–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã
        
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        """
        base_stats = self.indexer.get_collection_stats()
        
        enhanced_stats = {
            'enhanced_features': {
                'specialized_prompts': len(self.prompt_system.prompts),
                'query_types': [qt.value for qt in QueryType],
                'table_prioritization': True,
                'structured_output': True
            },
            'prompt_system': {
                'available_types': self.get_query_types()
            }
        }
        
        return {**base_stats, **enhanced_stats}

    def _enhanced_strain_search(self, query: str, strain_name: str) -> List[Dict[str, Any]]:
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —à—Ç–∞–º–º–µ
        """
        search_queries = [
            f"{strain_name}",  # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —à—Ç–∞–º–º–∞
            f"{strain_name} morphology characteristics",  # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
            f"{strain_name} growth conditions temperature pH",  # –£—Å–ª–æ–≤–∏—è —Ä–æ—Å—Ç–∞
            f"{strain_name} biochemical tests enzymes",  # –ë–∏–æ—Ö–∏–º–∏—è
            f"{strain_name} fatty acids lipids",  # –ñ–∏—Ä–Ω—ã–µ –∫–∏—Å–ª–æ—Ç—ã
            f"{strain_name} genome size genes",  # –ì–µ–Ω–æ–º
            f"{strain_name} isolation source origin",  # –ü—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ
        ]
        
        all_results = []
        seen_ids = set()
        
        for search_query in search_queries:
            logger.info(f"–ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {search_query}")
            results = self.indexer.search(search_query, top_k=8)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in results:
                chunk_id = result.get('metadata', {}).get('chunk_id', '')
                if chunk_id and chunk_id not in seen_ids:
                    seen_ids.add(chunk_id)
                    all_results.append(result)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-15
        all_results.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        return all_results[:15]

    def _extract_strain_name(self, query: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —à—Ç–∞–º–º–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        """
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π —à—Ç–∞–º–º–æ–≤
        patterns = [
            r'—à—Ç–∞–º–º[–µ]?\s+([A-Za-z0-9\-]+[T]?)',  # —à—Ç–∞–º–º GW1-59T
            r'([A-Za-z0-9\-]+[T])\s*[\.,]?',      # GW1-59T
            r'([A-Z]{1,3}[0-9]+\-[0-9]+[T]?)',    # GW1-59T
            r'([A-Z]+\-[0-9]+[T]?)',              # GW1-59T
        ]
        
        query_lower = query.lower()
        for pattern in patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                strain = match.group(1)
                logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —à—Ç–∞–º–º–∞: {strain}")
                return strain
        
        return ""
    
    def _validate_facts_in_answer(self, answer: str, relevant_chunks: List[Dict[str, Any]], query: str) -> str:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–∫—Ç—ã –≤ –æ—Ç–≤–µ—Ç–µ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—è—Ö
        
        Args:
            answer (str): –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            relevant_chunks (List[Dict[str, Any]]): –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            query (str): –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            str: –û—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏ –æ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—è—Ö
        """
        import re
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —à—Ç–∞–º–º–∞
        strain_name = self._extract_strain_name(query)
        if not strain_name:
            return answer
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è fact_checker
        evidence_chunks = []
        for chunk in relevant_chunks:
            chunk_data = {
                'text': chunk.get('text', ''),
                'metadata': chunk.get('metadata', {})
            }
            evidence_chunks.append(chunk_data)
        
        warnings = []
        validated_answer = answer
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        temp_patterns = [
            r'(\d+)\s*[‚Äì-]\s*(\d+)\s*¬∞C',
            r'–æ—Ç\s+(\d+)\s*¬∞C\s+–¥–æ\s+(\d+)\s*¬∞C',
            r'–æ—Ç\s+(\d+)\s+–¥–æ\s+(\d+)\s*¬∞C',
            r'–¥–∏–∞–ø–∞–∑–æ–Ω–µ\s+–æ—Ç\s+(\d+)\s+–¥–æ\s+(\d+)\s*¬∞C',
            r'–¥–∏–∞–ø–∞–∑–æ–Ω.*?–æ—Ç\s+(\d+).*?–¥–æ\s+(\d+)\s*¬∞C',
        ]
        
        for pattern in temp_patterns:
            matches = re.findall(pattern, answer)
            for match in matches:
                temp_claim = f"{match[0]}-{match[1]}¬∞C"
                fact_check = self.fact_checker.check_temperature_claim(
                    temp_claim, evidence_chunks, strain_name
                )
                
                if not fact_check.is_accurate and fact_check.confidence > 0.3:
                    warning = f"‚ö†Ô∏è **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ**: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω {temp_claim} –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏."
                    warnings.append(warning)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ pH –¥–∞–Ω–Ω—ã—Ö
        ph_patterns = [
            r'pH\s+(\d+[.,]\d+)\s*[‚Äì-]\s*(\d+[.,]\d+)',
            r'–æ—Ç\s+pH\s+(\d+[.,]\d+)\s+–¥–æ\s+(\d+[.,]\d+)',
        ]
        
        for pattern in ph_patterns:
            matches = re.findall(pattern, answer)
            for match in matches:
                ph_claim = f"pH {match[0]}-{match[1]}"
                fact_check = self.fact_checker.check_ph_claim(
                    ph_claim, evidence_chunks, strain_name
                )
                
                if not fact_check.is_accurate and fact_check.confidence > 0.3:
                    warning = f"‚ö†Ô∏è **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ**: pH –¥–∏–∞–ø–∞–∑–æ–Ω {ph_claim} –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏."
                    warnings.append(warning)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤ –∫–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞
        if warnings:
            validated_answer += "\n\n---\n**üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤:**\n\n" + "\n\n".join(warnings)
            validated_answer += "\n\n*–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏. –î–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.*"
        
        return validated_answer 